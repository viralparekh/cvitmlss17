{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a Tensor library with GPU support\n",
    "import torch\n",
    "\n",
    "#Datasets, Transforms and Models specific to Computer Vision\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#differentiation library that supports all differentiable Tensor operations in torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#a neural networks library integrated with autograd functionality\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#an optimization package with standard optimization methods such as SGD, RMSProp, LBFGS, Adam etc.\n",
    "import torch.optim as optim\n",
    "\n",
    "#Weight Initialization\n",
    "import torch.nn.init as weight_init\n",
    "\n",
    "#scientific computing library for Python\n",
    "import numpy as np\n",
    "\n",
    "#plotting and visualization library\n",
    "import matplotlib.pyplot as plt\n",
    "#Display on the notebook\n",
    "%matplotlib inline \n",
    "plt.ion() #Turn interactive mode on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train data\n",
    "#Compose transforms (applies data transformation and augmentation) prior to feeding to training\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "#inbuilt dataset class for reading CIFAR10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='../../data/', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "\n",
    "#dataloader for Batching, shuffling and loading data in parallel\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "#test data\n",
    "testset = torchvision.datasets.CIFAR10(root='../../data/', train=False,\n",
    "                                       download=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model (\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool_1): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool_2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (fc1): Linear (400 -> 120)\n",
      "  (fc2): Linear (120 -> 84)\n",
      "  (fc3): Linear (84 -> 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This scheme can be one of 'uniform', 'normal', 'constant' 'Xavier' and 'custom'\n",
    "\n",
    "weight_initialization_scheme = 'custom'\n",
    "\n",
    "\n",
    "def weight_init_custom_conv(module):\n",
    "    import math\n",
    "    n = module.kernel_size[0] * module.kernel_size[1] * module.out_channels\n",
    "    module.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "\n",
    "def weight_init_custom_linear(module):\n",
    "    import math\n",
    "#     import pdb\n",
    "#     pdb.set_trace()\n",
    "    n = module.in_features * module.out_features\n",
    "    module.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "\n",
    "    \n",
    "class Model(nn.Module):\n",
    "    \n",
    "    #define the learnable paramters by calling the respective modules (nn.Conv2d, nn.MaxPool2d etc.)\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        #calling conv2d module for convolution\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5,stride=1,padding=0,bias=True)\n",
    "        \n",
    "        #calling MaxPool2d module for max pooling with downsampling of 2\n",
    "        self.pool_1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.pool_2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        #fully connected layers\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)   \n",
    "        \n",
    "        \n",
    "        # Setting the weights for the conv1 layer\n",
    "        for m in self.modules():\n",
    "            if weight_initialization_scheme == 'uniform':\n",
    "#                     print('Initializating with uniform scheme')\n",
    "                    weight_init.uniform(self.conv1.weight)\n",
    "                    weight_init.uniform(self.conv2.weight)\n",
    "                    weight_init.uniform(self.fc1.weight)\n",
    "                    weight_init.uniform(self.fc2.weight)\n",
    "                    weight_init.uniform(self.fc3.weight)\n",
    "            if weight_initialization_scheme == 'normal':\n",
    "#                     print('Initializating with normal scheme')\n",
    "                    weight_init.normal(self.conv1.weight)\n",
    "                    weight_init.normal(self.conv2.weight)\n",
    "                    weight_init.normal(self.fc1.weight)\n",
    "                    weight_init.normal(self.fc2.weight)\n",
    "                    weight_init.normal(self.fc3.weight)\n",
    "            if weight_initialization_scheme == 'constant':\n",
    "#                     print('Initializating with constant scheme')\n",
    "                    weight_init.constant(self.conv1.weight, 0.1)\n",
    "                    weight_init.constant(self.conv2.weight, 0.1)\n",
    "                    weight_init.constant(self.fc1.weight, 0.1)\n",
    "                    weight_init.constant(self.fc2.weight, 0.1)\n",
    "                    weight_init.constant(self.fc3.weight, 0.1)\n",
    "            if weight_initialization_scheme == 'Xavier':\n",
    "#                     print('Initializating with Xavier scheme')\n",
    "                    weight_init.xavier_normal(self.conv1.weight)\n",
    "                    weight_init.xavier_normal(self.conv2.weight)\n",
    "                    weight_init.xavier_normal(self.fc1.weight)\n",
    "                    weight_init.xavier_normal(self.fc2.weight)\n",
    "                    weight_init.xavier_normal(self.fc3.weight)\n",
    "            if weight_initialization_scheme == 'custom':\n",
    "#                     print('Initializating with custom scheme')\n",
    "                    weight_init_custom_conv(self.conv1)\n",
    "                    weight_init_custom_conv(self.conv2)\n",
    "                    weight_init_custom_linear(self.fc1)\n",
    "                    weight_init_custom_linear(self.fc2)\n",
    "                    weight_init_custom_linear(self.fc3)\n",
    "                    \n",
    "\n",
    "\n",
    "    \n",
    "    #defining the structure of the network\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #Applying relu activation after each conv layer\n",
    "        x = self.pool_1(F.relu(self.conv1(x)))\n",
    "        x = self.pool_2(F.relu(self.conv2(x)))\n",
    "        \n",
    "        #reshaping to 1d for giving input to fully connected units\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = Model()\n",
    "model = model.cuda()\n",
    "\n",
    "#Printing the network architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | loss: 1.9786080098319054 | accuracy: 0.25646\n",
      "Epoch: 1 | loss: 1.990701961004734 | accuracy: 0.25672\n",
      "Epoch: 2 | loss: 1.9934690431499482 | accuracy: 0.24806\n",
      "Epoch: 3 | loss: 2.0341439950466156 | accuracy: 0.22056\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        total_loss += loss.data[0]\n",
    "        # Calculate no of correct classifications\n",
    "        _, predicted_class = outputs.max(1)\n",
    "        correct += predicted_class.data.eq(labels.data).sum()     \n",
    "        \n",
    "    print(\"Epoch: {0} | loss: {1} | accuracy: {2}\".format(epoch, total_loss/len(train_loader)\n",
    "                                                          , correct/len(train_loader.dataset)))              "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
