{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a Tensor library with GPU support\n",
    "import torch\n",
    "\n",
    "#Datasets, Transforms and Models specific to Computer Vision\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#differentiation library that supports all differentiable Tensor operations in torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#a neural networks library integrated with autograd functionality\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#an optimization package with standard optimization methods such as SGD, RMSProp, LBFGS, Adam etc.\n",
    "import torch.optim as optim\n",
    "\n",
    "#Weight Initialization\n",
    "import torch.nn.init as weight_init\n",
    "\n",
    "# import nn module\n",
    "import torch.nn as nn\n",
    "\n",
    "#scientific computing library for Python\n",
    "import numpy as np\n",
    "\n",
    "#plotting and visualization library\n",
    "import matplotlib.pyplot as plt\n",
    "#Display on the notebook\n",
    "%matplotlib inline \n",
    "plt.ion() #Turn interactive mode on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train data\n",
    "#Compose transforms (applies data transformation and augmentation) prior to feeding to training\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "#inbuilt dataset class for reading CIFAR10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='../../data/', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "\n",
    "#dataloader for Batching, shuffling and loading data in parallel\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "#test data\n",
    "testset = torchvision.datasets.CIFAR10(root='../../data/', train=False,\n",
    "                                       download=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model (\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool_1): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool_2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (fc1): Linear (400 -> 120)\n",
      "  (fc2): Linear (120 -> 84)\n",
      "  (fc3): Linear (84 -> 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        #calling conv2d module for convolution\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5,stride=1,padding=0,bias=True)\n",
    "        \n",
    "        #calling MaxPool2d module for max pooling with downsampling of 2\n",
    "        self.pool_1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.pool_2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        #fully connected layers\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)   \n",
    "     \n",
    "    #defining the structure of the network\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #Applying relu activation after each conv layer\n",
    "        x = self.pool_1(F.relu(self.conv1(x)))\n",
    "        x = self.pool_2(F.relu(self.conv2(x)))\n",
    "        \n",
    "        #reshaping to 1d for giving input to fully connected units\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = Model()\n",
    "model = model.cuda()\n",
    "\n",
    "#Printing the network architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization scheme can be 'sgd', 'RMSProp', 'Adam', 'Adadelta', 'Adagrad'\n",
    "optimization_scheme = \"Adagrad\"\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if optimization_scheme == 'sgd':\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "elif optimization_scheme == 'RMSProp':\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=0.001, weight_decay=0)\n",
    "elif optimization_scheme == \"Adadelta\":\n",
    "     optimizer = optim.Adadelta(model.parameters(), lr=0.001, weight_decay=0)\n",
    "elif optimization_scheme == \"Adam\":\n",
    "     optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0)\n",
    "elif optimization_scheme == \"Adagrad\":\n",
    "     optimizer = optim.Adagrad(model.parameters(), lr=0.001, weight_decay=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | loss: 1.964628552980423 | accuracy: 0.2911\n",
      "Epoch: 1 | loss: 1.837211944322586 | accuracy: 0.33892\n",
      "Epoch: 2 | loss: 1.7927695668983459 | accuracy: 0.35654\n",
      "Epoch: 3 | loss: 1.7620282832193375 | accuracy: 0.36678\n",
      "Epoch: 4 | loss: 1.737305153274536 | accuracy: 0.37478\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        total_loss += loss.data[0]\n",
    "        # Calculate no of correct classifications\n",
    "        _, predicted_class = outputs.max(1)\n",
    "        correct += predicted_class.data.eq(labels.data).sum()     \n",
    "        \n",
    "    print(\"Epoch: {0} | loss: {1} | accuracy: {2}\".format(epoch, total_loss/len(train_loader)\n",
    "                                                          , correct/len(train_loader.dataset)))              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
