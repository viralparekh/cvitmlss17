{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3: Auxiliary Classifier GANs\n",
    "\n",
    "(Link to paper: https://arxiv.org/abs/1610.09585)\n",
    "\n",
    "Auxiliary Classifier GANs are supervised networks for generating images. They are quite similar to C-GANs. The difference is in the discriminator. Instead of passing the conditional variable as input, the discriminator is made to predict the conditonal variable, along with the adversarial real vs. fake.\n",
    "\n",
    "![](ACGAN.PNG)\n",
    "\n",
    "The paper claims that this set-up jproduces 128 Ã— 128 resolution image samples exhibiting global coherence and structure (This is a problem with earlier GANs). However, as we are using the MNIST dataset, we will not be able to see this in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "%matplotlib inline\n",
    "\n",
    "mb_size = 32\n",
    "z_dim = 16\n",
    "X_dim = 784\n",
    "y_dim = 10\n",
    "h_dim = 128\n",
    "cnt = 0\n",
    "lr = 1e-3\n",
    "eps = 1e-8\n",
    "\n",
    "setcuda = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use one-hot encoding similar to conditonal GANs. Here, we load the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "\n",
    "# load the dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0,), (1,))])\n",
    "trainset = torchvision.datasets.MNIST(root='../../data/lab3', train=True,\n",
    "                                        download=False,transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=mb_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "classes = ('0','1','2','3','4','5','6','7','8','9')\n",
    "\n",
    "def onehotencoder(x):\n",
    "    y = np.zeros((x.numpy().shape[0],10))\n",
    "    for i in range(x.numpy().shape[0]):\n",
    "        y[i,x[i]] = 1\n",
    "    return y\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "import pdb\n",
    "def mnist_next(dataiter):\n",
    "\n",
    "    try:\n",
    "        images, labels = dataiter.next()\n",
    "        labels = onehotencoder(labels)\n",
    "        images = images.view(images.numpy().shape[0],28*28)\n",
    "    except:\n",
    "        dataiter = iter(trainloader)\n",
    "        images, labels = dataiter.next()\n",
    "        labels = onehotencoder(labels)\n",
    "        images = images.view(images.numpy().shape[0],28*28)\n",
    "    return images.numpy(), labels\n",
    "\n",
    "def initialize_loader(trainset):\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=mb_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "    dataiter = iter(trainloader)\n",
    "    return dataiter\n",
    "\n",
    "images, labels = mnist_next(dataiter)\n",
    "# print some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "img = torchvision.utils.make_grid(images)\n",
    "npimg = img.numpy()\n",
    "plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define the generator network. The input to the network is a concatenation of the noise vector and the class vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_ = torch.nn.Sequential(\n",
    "    torch.nn.Linear(z_dim + y_dim, h_dim),\n",
    "    torch.nn.PReLU(),\n",
    "    torch.nn.Linear(h_dim, X_dim),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "\n",
    "def G(z, c):\n",
    "    inputs = torch.cat([z, c], 1)\n",
    "    return G_(inputs)\n",
    "\n",
    "if setcuda:\n",
    "    G_.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discriminator network has an interesting structure. It has a shared part, which branches into two parts: D_gan and D_aux. D_gan predicts real/fake while D_aux predicts the class label. \n",
    "\n",
    "If we look at the forward(), the input image is first processed by D_shared. The output of it is passed to both D_aux and D_gan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_shared = torch.nn.Sequential(\n",
    "    torch.nn.Linear(X_dim, h_dim),\n",
    "    torch.nn.PReLU()\n",
    ")\n",
    "\n",
    "D_gan = torch.nn.Sequential(\n",
    "    torch.nn.Linear(h_dim, 1),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "D_aux = torch.nn.Sequential(\n",
    "    torch.nn.Linear(h_dim, y_dim),\n",
    "    torch.nn.Softmax()\n",
    ")\n",
    "\n",
    "\n",
    "def D(X):\n",
    "    h = D_shared(X)\n",
    "    return D_gan(h), D_aux(h)\n",
    "\n",
    "if setcuda:\n",
    "    D_shared = D_shared.cuda()\n",
    "    D_gan = D_gan.cuda()\n",
    "    D_aux = D_aux.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us get the parameters of all the networks and create the solvers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nets = [G_, D_shared, D_gan, D_aux]\n",
    "\n",
    "G_params = G_.parameters()\n",
    "D_params = (list(D_shared.parameters()) + list(D_gan.parameters()) +\n",
    "            list(D_aux.parameters()))\n",
    "\n",
    "\n",
    "def reset_grad():\n",
    "    for net in nets:\n",
    "        net.zero_grad()\n",
    "\n",
    "\n",
    "G_solver = optim.Adam(G_params, lr=lr)\n",
    "D_solver = optim.Adam(D_params, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us train the AC-GAN. The loss of the discriminator is loss of D_gan + loss of D_aux. Loss of generator is loss of D_aux - loss of D_gan. This means the aim of the generator is to fool the discriminator into thinking it is real and to produce images from the correct class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = initialize_loader(trainset)\n",
    "\n",
    "for it in range(10000):\n",
    "    # Sample data\n",
    "#     pdb.set_trace()\n",
    "    X, y = mnist_next(dataiter)\n",
    "    \n",
    "#     if X.shape[0]!=mb_size:\n",
    "#         continue\n",
    "        \n",
    "    if setcuda:\n",
    "        X = Variable(torch.from_numpy(X).cuda())\n",
    "        c = Variable(torch.from_numpy(y.astype('float32')).cuda())\n",
    "        y_true = Variable(torch.from_numpy(y.argmax(axis=1).astype('int')).cuda())\n",
    "        z = Variable(torch.randn(mb_size, z_dim).cuda())\n",
    "    else:\n",
    "        X = Variable(torch.from_numpy(X))\n",
    "        # c is one-hot\n",
    "        c = Variable(torch.from_numpy(y.astype('float32')))\n",
    "        # y_true is not one-hot (requirement from nn.cross_entropy)\n",
    "        y_true = Variable(torch.from_numpy(y.argmax(axis=1).astype('int')))\n",
    "        # z noise\n",
    "        z = Variable(torch.randn(mb_size, z_dim))\n",
    "\n",
    "    \"\"\" Discriminator \"\"\"\n",
    "    G_sample = G(z, c)\n",
    "    D_real, C_real = D(X)\n",
    "    D_fake, C_fake = D(G_sample)\n",
    "\n",
    "    # GAN's D loss\n",
    "    D_loss = torch.mean(torch.log(D_real + eps) + torch.log(1 - D_fake + eps))\n",
    "    # Cross entropy aux loss\n",
    "    C_loss = -nn.cross_entropy(C_real, y_true) - nn.cross_entropy(C_fake, y_true)\n",
    "\n",
    "    # Maximize\n",
    "    DC_loss = -(D_loss + C_loss)\n",
    "\n",
    "    DC_loss.backward()\n",
    "    D_solver.step()\n",
    "\n",
    "    reset_grad()\n",
    "\n",
    "    \"\"\" Generator \"\"\"\n",
    "    G_sample = G(z, c)\n",
    "    D_fake, C_fake = D(G_sample)\n",
    "    _, C_real = D(X)\n",
    "\n",
    "    # GAN's G loss\n",
    "    G_loss = torch.mean(torch.log(D_fake + eps))\n",
    "    # Cross entropy aux loss\n",
    "    C_loss = -nn.cross_entropy(C_real, y_true) - nn.cross_entropy(C_fake, y_true)\n",
    "\n",
    "    # Maximize\n",
    "    GC_loss = -(G_loss + C_loss)\n",
    "\n",
    "    GC_loss.backward()\n",
    "    G_solver.step()\n",
    "\n",
    "    reset_grad()\n",
    "\n",
    "    # Print and plot every now and then\n",
    "    if it % 1000 == 0:\n",
    "        idx = np.random.randint(0, 10)\n",
    "        c = np.zeros([16, y_dim])\n",
    "        c[range(16), idx] = 1\n",
    "        c = Variable(torch.from_numpy(c.astype('float32')))\n",
    "\n",
    "\n",
    "        print('Iter-{}; D_loss: {:.4}; G_loss: {:.4}; Idx: {}'\n",
    "              .format(it, -D_loss.data[0], -G_loss.data[0], idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see the images produced by this network. At testing time, we can see that it is similar to C-GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "if setcuda:\n",
    "    z = Variable(torch.randn(mb_size, z_dim).cuda())\n",
    "    discr_codes = Variable(torch.zeros(mb_size,10).cuda())\n",
    "else:\n",
    "    z = Variable(torch.randn(mb_size, z_dim))\n",
    "    discr_codes = Variable(torch.zeros(mb_size, 10))\n",
    "discr_codes[:,0] = 1 \n",
    "samples = G(z,discr_codes)\n",
    "samples = samples.cpu()\n",
    "img = samples.data\n",
    "img = img.view([mb_size,1,28,28])\n",
    "img = torchvision.utils.make_grid(img)\n",
    "img = img.permute(1,2,0)\n",
    "plt.imshow(img.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions/Exercises\n",
    "\n",
    "<ol>\n",
    "<li> How does AC-GAN compare to C-GAN in terms of\n",
    "<ol>\n",
    "<li> Quality of images</li>\n",
    "<li>Training time</li>\n",
    "<li>Stability of loss function</li>\n",
    "</ol></li>\n",
    "<li> Can you think of a way to add some attributes along with the classification vector? </li>\n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
