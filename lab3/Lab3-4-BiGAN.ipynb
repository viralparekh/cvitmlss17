{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4: BiGANs\n",
    "\n",
    "(link to paper: https://arxiv.org/abs/1605.09782)\n",
    "\n",
    "In vanilla GANs, we saw that the generator could generate a wide variety of images, but we had no control over the type of images generated.\n",
    "\n",
    "In C-GAN and AC-GAN, we saw that we can gain some control over the type of images to be generated. \n",
    "\n",
    "BiGAN solves the problem of getting the latent variable given an image. This is the inference problem. BiGANs can be used for feature learning. Here is a diagram of BiGAN:\n",
    "\n",
    "![](BiGAN.png)\n",
    "\n",
    "There are three networks in the BiGAN. The generator network G converts noise input into images. The discriminator network D determines whether the input is real or fake. The encoder network E converts the image back into the latent variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "from itertools import *\n",
    "%matplotlib inline\n",
    "\n",
    "mb_size = 64\n",
    "z_dim = 10\n",
    "X_dim = 784\n",
    "y_dim = 10\n",
    "h_dim = 128\n",
    "cnt = 0\n",
    "lr = 1e-3\n",
    "\n",
    "\n",
    "def log(x):\n",
    "    return torch.log(x + 1e-8)\n",
    "\n",
    "setcuda = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use MNIST dataset for this example. This is purely unsupervised, and we do not need to use the labels for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a transformation to resize the image to 64x64\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# load the dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0,), (1,))])\n",
    "trainset = torchvision.datasets.MNIST(root='../../data/lab3', train=True,\n",
    "                                        download=False,transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=mb_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "classes = ('0','1','2','3','4','5','6','7','8','9')\n",
    "\n",
    "def onehotencoder(x):\n",
    "    y = np.zeros((x.numpy().shape[0],10))\n",
    "    for i in range(x.numpy().shape[0]):\n",
    "        y[i,x[i]] = 1\n",
    "    return y\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "def mnist_next(dataiter):\n",
    "\n",
    "    try:\n",
    "        images, labels = dataiter.next()\n",
    "        labels = onehotencoder(labels)\n",
    "        images = images.view(images.numpy().shape[0],28*28)\n",
    "    except:\n",
    "        dataiter = iter(trainloader)\n",
    "        images, labels = dataiter.next()\n",
    "        labels = onehotencoder(labels)\n",
    "        images = images.view(images.numpy().shape[0],28*28)\n",
    "    return images.numpy(), labels\n",
    "\n",
    "def initialize_loader(trainset):\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=mb_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "    dataiter = iter(trainloader)\n",
    "    return dataiter\n",
    "\n",
    "images, labels = mnist_next(dataiter)\n",
    "# print some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "img = torchvision.utils.make_grid(images)\n",
    "npimg = img.numpy()\n",
    "plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define the three networks, Q(inference network), P(generator network) and D(discriminator network. Note that I am using a class notation for defining Q. This is so that I can get the feature representation if I want. A function getfeature() is defined for this purpose. \n",
    "\n",
    "We use ADAM solver to train BiGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inference net (Encoder) Q(z|X)\n",
    "# Q = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(X_dim, h_dim),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(h_dim, z_dim)\n",
    "# )\n",
    "\n",
    "class Q_(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Q_, self).__init__()\n",
    "        self.layer1 = torch.nn.Linear(X_dim, h_dim)\n",
    "        self.layer2 = torch.nn.ReLU()\n",
    "        self.layer3 = torch.nn.Linear(h_dim, z_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        l1 = self.layer1(x)\n",
    "        l2 = self.layer2(l1)\n",
    "        l3 = self.layer3(l2)\n",
    "        return l3\n",
    "    \n",
    "    def getfeature(self, x):\n",
    "        l1 = self.layer1(x)\n",
    "        l2 = self.layer2(l1)\n",
    "        return l2\n",
    "Q = Q_()\n",
    "\n",
    "# Generator net (Decoder) P(X|z)\n",
    "P = torch.nn.Sequential(\n",
    "    torch.nn.Linear(z_dim, h_dim),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(h_dim, X_dim),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "D_ = torch.nn.Sequential(\n",
    "    torch.nn.Linear(X_dim + z_dim, h_dim),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(h_dim, 1),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "\n",
    "def D(X, z):\n",
    "    return D_(torch.cat([X, z], 1))\n",
    "\n",
    "\n",
    "def reset_grad():\n",
    "    Q.zero_grad()\n",
    "    P.zero_grad()\n",
    "    D_.zero_grad()\n",
    "\n",
    "if setcuda:\n",
    "    Q = Q.cuda()\n",
    "    P = P.cuda()\n",
    "    D_ = D_.cuda()\n",
    "\n",
    "G_solver = optim.Adam(chain(Q.parameters(), P.parameters()), lr=lr)\n",
    "D_solver = optim.Adam(D_.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us train the network. The network is trained in two steps. \n",
    "\n",
    "In the first step, we update the weights of the discriminator. Some real images are passed to the encoder to get the fake latent variables. Some random noise is passed to the generator to get the fake (generated) images. Both of these are passed to the discriminator to get the discriminator loss. This is backpropagated to update the discriminator weight. \n",
    "\n",
    "A similar thing is done for the generator and encoder weights. Note that they are optimized together using 'chain' in the code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = initialize_loader(trainset)\n",
    "\n",
    "for it in range(1000):\n",
    "    # Sample data\n",
    "    z = Variable(torch.randn(mb_size, z_dim))\n",
    "    X, _ = mnist_next(dataiter)\n",
    "    if X.shape[0]!=mb_size:\n",
    "        dataiter = initialize_loader(trainset)\n",
    "        X,_ = mnist_next(dataiter)\n",
    "    X = Variable(torch.from_numpy(X))\n",
    "    \n",
    "    if setcuda:\n",
    "        z = z.cuda()\n",
    "        X = X.cuda()\n",
    "\n",
    "    # Discriminator\n",
    "    z_hat = Q(X)\n",
    "    X_hat = P(z)\n",
    "\n",
    "    D_enc = D(X, z_hat)\n",
    "    D_gen = D(X_hat, z)\n",
    "\n",
    "    D_loss = -torch.mean(log(D_enc) + log(1 - D_gen))\n",
    "\n",
    "    D_loss.backward()\n",
    "    D_solver.step()\n",
    "    G_solver.step()\n",
    "    reset_grad()\n",
    "\n",
    "    # Autoencoder Q, P\n",
    "    z_hat = Q(X)\n",
    "    X_hat = P(z)\n",
    "\n",
    "    D_enc = D(X, z_hat)\n",
    "    D_gen = D(X_hat, z)\n",
    "\n",
    "    G_loss = -torch.mean(log(D_gen) + log(1 - D_enc))\n",
    "\n",
    "    G_loss.backward()\n",
    "    G_solver.step()\n",
    "    reset_grad()\n",
    "\n",
    "    # Print and plot every now and then\n",
    "    if it % 1000 == 0:\n",
    "        print('Iter-{}; D_loss: {:.4}; G_loss: {:.4}'\n",
    "              .format(it, D_loss.data[0], G_loss.data[0]))\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see the kind of images produced by the generator network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "z = Variable(torch.randn(mb_size, z_dim))\n",
    "if setcuda:\n",
    "    z = z.cuda()\n",
    "samples = P(z)\n",
    "samples = samples.cpu()\n",
    "img = samples.data\n",
    "img = img.view([mb_size,1,28,28])\n",
    "img = torchvision.utils.make_grid(img)\n",
    "img = img.permute(1,2,0)\n",
    "plt.imshow(img.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see how good the encoder is. First we get some samples from the MNIST dataset. Then we pass it through the encoder network to get the latent encoding. We then pass the latent vector to the generator to see if the generator can get the image we started with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _ = mnist_next(dataiter)\n",
    "img = torch.from_numpy(img)\n",
    "img1 = img.view(64,1,28,28)\n",
    "img1 = img1.repeat(1,3,1,1)\n",
    "img1 = torchvision.utils.make_grid(img1)\n",
    "img1 = img1.permute(1,2,0)\n",
    "plt.figure()\n",
    "plt.imshow(img1.numpy())\n",
    "if setcuda:\n",
    "    img = img.cuda()\n",
    "encodedvariable = Q(Variable(img))\n",
    "decoded = P(encodedvariable)\n",
    "decoded = decoded.cpu()\n",
    "decoded = decoded.data\n",
    "decoded = decoded.view(64,1,28,28)\n",
    "decoded = decoded.repeat(1,3,1,1)\n",
    "decoded = torchvision.utils.make_grid(decoded)\n",
    "decoded = decoded.permute(1,2,0)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(decoded.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results will get better with more training.\n",
    "\n",
    "### Questions/Exercises\n",
    "<ol>\n",
    "<li> Can you think of a way to gradually transition (morph) between two images using BiGANs? </li>\n",
    "<li> How can BiGAN be helpful in classification?</li>\n",
    "<li> (On your own time) BiGANs can be used to do image arithmetic! (As shown here: https://github.com/soumith/dcgan.torch scroll down to section 'Vector Arithmetic') Train a BiGAN using a face image dataset. How will you do the vector arithmetic?</li>\n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
