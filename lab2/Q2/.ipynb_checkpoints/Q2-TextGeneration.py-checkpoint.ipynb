{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating text using RNNs ###\n",
    "- an RNN  is trained in seq2seq manner to make it learn to generate text\n",
    "- with lots of text fed to the network it models the language\n",
    "- it learns to model the conditional probability of having a character as next character, given its previous N characters\n",
    "- This code does the unrolling of RNN explicitly using a for loop\n",
    "\n",
    "\n",
    "<b>Acknowledgement :</b>- This code is almost completely copied from here https://gist.github.com/michaelklachko?direction=desc&sort=updated . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import time, math\n",
    " \n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if use_cuda:\n",
    "    print ('CUDA is available')\n",
    "#use_cuda=False   #uncomment this if you dont want to use cuda variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RNN on The Complete Sherlock Holmes.\n",
      "\n",
      "\n",
      "File length: 3867934 characters\n",
      "Unique characters: 52\n",
      "\n",
      "Unique characters: ['\\n', ' ', '!', '\"', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "('no of uniq chars', 52)\n"
     ]
    }
   ],
   "source": [
    "printable = string.printable\n",
    " \n",
    "#Input text is available here: https://sherlock-holm.es/stories/plain-text/cano.txt\n",
    "text = open('../../../data/lab2/sh.txt', 'r').read().lower()\n",
    "\n",
    "\n",
    "\n",
    "## remove non printable chars and other unnecessary punctuations\n",
    "pruned_text = ''\n",
    " \n",
    "for c in text:\n",
    "\tif c in printable and c not in '{}[]&_':\n",
    "\t\tpruned_text += c\n",
    " \n",
    "text = pruned_text\t\t  \n",
    "file_len = len(text)\n",
    "alphabet = sorted(list(set(text)))\n",
    "n_chars = len(alphabet)\n",
    "\n",
    "print \"\\nTraining RNN on The Complete Sherlock Holmes.\\n\"\t\t \n",
    "print \"\\nFile length: {:d} characters\\nUnique characters: {:d}\".format(file_len, n_chars)\n",
    "print \"\\nUnique characters:\", alphabet\t\t \n",
    "print ('no of uniq chars', n_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_since(since):\n",
    "\ts = time.time() - since\n",
    "\tm = math.floor(s / 60)\n",
    "\ts -= m * 60\n",
    "\treturn '%dm %ds' % (m, s)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_chunk():\n",
    "    start = random.randint(0, file_len - chunk_len)\n",
    "    end = start + chunk_len + 1\n",
    "    return text[start:end]\n",
    " \n",
    "def chunk_vector(chunk):\n",
    "    vector = torch.zeros(len(chunk)).long()\n",
    "    for i, c in enumerate(chunk):\n",
    "        vector[i] = alphabet.index(c)  #construct ASCII vector for chunk, one number per character\n",
    "    \n",
    "    if use_cuda:\n",
    "        return Variable(vector.cuda(), requires_grad=False) \n",
    "    else:\n",
    "        \n",
    "         return Variable(vector, requires_grad=False) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_training_batch():\n",
    "\tinputs = []\n",
    "\ttargets = []\n",
    "\t#construct list of input vectors (chunk_len):\n",
    "\tfor b in range(batch_size):    \n",
    "\t\tchunk = random_chunk()\n",
    "\t\tinp = chunk_vector(chunk[:-1])\n",
    "\t\ttarget = chunk_vector(chunk[1:])\n",
    "\t\tinputs.append(inp)\n",
    "\t\ttargets.append(target)\n",
    "\t#construct batches from lists (chunk_len, batch_size):\n",
    "\t#need .view to handle batch_size=1\n",
    "\t#need .contiguous to allow .view later\n",
    "\tinp = torch.cat(inputs, 0).view(batch_size, chunk_len).t().contiguous()\n",
    "\ttarget = torch.cat(targets, 0).view(batch_size, chunk_len).t().contiguous()\n",
    "\treturn inp, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers):\n",
    "        super(RNN, self).__init__()\n",
    "         \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers \n",
    "        self.batch_size = batch_size\n",
    "         \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size) #first arg is dictionary size\n",
    "        self.GRU = nn.GRU(hidden_size, hidden_size, n_layers)  #(input_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "         \n",
    "    def forward(self, input, hidden, batch_size):\n",
    "\n",
    "        input = self.encoder(input.view(batch_size, seq_len)) \n",
    "        #need to reshape Input to (seq_len, batch, hidden_size)\n",
    "        input = input.permute(1, 0, 2)\n",
    "\n",
    "        output, hidden = self.GRU(input, hidden) \n",
    "\n",
    "        output = self.decoder(output.view(batch_size, hidden_size))  \n",
    "        #now the output is (batch_size, output_size)\n",
    "        return output, hidden\n",
    "    def init_hidden(self, batch_size):\n",
    "        #Hidden (num_layers * num_directions, batch, hidden_size), num_directions = 2 for BiRNN\n",
    "        if use_cuda:\n",
    "\n",
    "            return Variable(torch.randn(self.n_layers, batch_size, self.hidden_size).cuda())\n",
    "        else:\n",
    "            return Variable(torch.randn(self.n_layers, batch_size, self.hidden_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model parameters:\n",
      "\n",
      "n_batches: 800\n",
      "batch_size: 64\n",
      "chunk_len: 128\n",
      "hidden_size: 256\n",
      "n_layers: 2\n",
      "LR: 0.0050\n",
      "\n",
      "\n",
      "Random chunk of text:\n",
      "\n",
      "ge may come during the day, though wiggins was despondent\n",
      "     about it last night. i want you to open all notes and telegrams, a \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nTake input, target pairs of chunks (target is shifted forward by a single character)\\nconvert them into chunk vectors\\nfor each char pair (i, t) in chunk vectors (input, target), create embeddings with dim = hidden_size\\nfeed input char vectors to GRU model, and compute error = output - target\\nupdate weights after going through all chars in the chunk\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 1\t\t   #each character is encoded as a single integer\n",
    "chunk_len = 128    #number of characters in a single text sample\n",
    "batch_size = 64   #number of text samples in a batch\n",
    "n_batches =800   #size of training dataset (total number of batches)\n",
    "hidden_size = 256  #width of model\n",
    "n_layers = 2\t  #depth of model\n",
    "LR = 0.005\t\t   #learning rate\n",
    " \n",
    "net = RNN(n_chars, hidden_size, n_chars, n_layers)\n",
    "#net = RNN(n_chars, hidden_size, n_chars, n_layers)\n",
    "optim = torch.optim.Adam(net.parameters(), LR)\n",
    "cost = nn.CrossEntropyLoss()  \n",
    "\n",
    "if use_cuda:\n",
    "    net=net.cuda()\n",
    "    cost=cost.cuda()\n",
    "\n",
    "print \"\\nModel parameters:\\n\"\n",
    "print \"n_batches: {:d}\\nbatch_size: {:d}\\nchunk_len: {:d}\\nhidden_size: {:d}\\nn_layers: {:d}\\nLR: {:.4f}\\n\".format(n_batches, batch_size, chunk_len, hidden_size, n_layers, LR)\n",
    "print \"\\nRandom chunk of text:\\n\\n\", random_chunk(), '\\n'\n",
    "\t \n",
    "\"\"\"\n",
    "Take input, target pairs of chunks (target is shifted forward by a single character)\n",
    "convert them into chunk vectors\n",
    "for each char pair (i, t) in chunk vectors (input, target), create embeddings with dim = hidden_size\n",
    "feed input char vectors to GRU model, and compute error = output - target\n",
    "update weights after going through all chars in the chunk\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(prime_str = 'elementary my dear watson', predict_len = 250, temp = 0.8, batch_size = 1):\n",
    "\thidden = net.init_hidden(batch_size) \n",
    "\tprime_input = chunk_vector(prime_str)\n",
    "\tpredicted = prime_str\n",
    "\t \n",
    "\tfor i in range(len(prime_str)-1):\n",
    "\t\t_, hidden = net(prime_input[i], hidden, batch_size)\n",
    "\t  \n",
    "\tinp = prime_input[-1]\n",
    "\t \n",
    "\tfor i in range(predict_len):\n",
    "\t\toutput, hidden = net(inp, hidden, batch_size)\n",
    "\t\toutput_dist = output.data.view(-1).div(temp).exp()\t\n",
    "\t\ttop_i = torch.multinomial(output_dist, 1)[0]\n",
    "\t\t \n",
    "\t\tpredicted_char = alphabet[top_i]\n",
    "\t\tpredicted +=  predicted_char\n",
    "\t\tinp = chunk_vector(predicted_char)\n",
    " \n",
    "\treturn predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sample output:\n",
      "\n",
      "you are them and a words and he could not does any suspected to his eyes alias short and\n",
      "     all constable \n",
      "\n",
      "[0m 21s (0 / 800) loss: 1.2022]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/minesh.mathew/.local/lib/python2.7/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sample output:\n",
      "\n",
      "you are all the gruff in a position. i remember we\n",
      "     such a dreadful neglis else and what had end\n",
      "     b \n",
      "\n",
      "[1m 15s (100 / 800) loss: 1.1863]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for iter in range(0,10):\n",
    "\ttraining_set = []\n",
    " \n",
    "\tfor i in range(n_batches):\n",
    "\t\ttraining_set.append((random_training_batch()))\n",
    " \n",
    "\ti = 0\t\n",
    "\tfor inp, target in training_set:\n",
    "\t\t#re-init hidden outputs, zero grads, zero loss:\n",
    "\t\thidden = net.init_hidden(batch_size)\n",
    "\t\tnet.zero_grad()\n",
    "\t\tloss = 0\t   \n",
    "\t\t#for each char in a chunk:\n",
    "\t\t#compute output, error, loss:\n",
    "\t\tcount=0\n",
    "\t\tfor c, t in zip(inp, target):\n",
    "\t\t\t#print( 'size of c')\n",
    "\t\t\t#print(c.size())\n",
    "\t\t\tcount=count+1\n",
    "\t\t\toutput, hidden = net(c, hidden, batch_size)\n",
    "\t\t\tloss += cost(output, t)\n",
    "\t\t#calculate gradients, update weights:\n",
    "\t\t#print('count was')\n",
    "\t\t#print (count)\n",
    "\t\tloss.backward()\n",
    "\t\toptim.step()\n",
    " \n",
    "\t\tif i % 100 == 0:\n",
    "\t\t\tprint \"\\n\\nSample output:\\n\"\n",
    "\t\t\tprint evaluate('you are', 100, 0.8), '\\n'\n",
    "\t\t\tprint('[%s (%d / %d) loss: %.4f]' % (time_since(start), i, n_batches, loss.data[0] / chunk_len))\n",
    " \t\t\twith open(\"model_iteration_iter_%d_i_%d.pth\"%(iter, i), \"w+\") as fp:\n",
    "\t\t\t\ttorch.save(net, fp)\n",
    " \n",
    "\t\ti += 1\n",
    "\t#print('i is')\n",
    "\t\n",
    "\t#print (i)\n",
    "\tprint ( 'completed iteration no.=', iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
