{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating text using RNNs ###\n",
    "- an RNN  is trained in seq2seq manner to make it learn to generate text\n",
    "- with lots of text fed to the network it models the language\n",
    "- it learns to model the conditional probability of having a character as next character, given its previous N characters\n",
    "- This code does the unrolling of RNN explicitly using a for loop\n",
    "\n",
    "\n",
    "<b>Acknowledgement :</b>- This code is almost completely copied from here https://gist.github.com/michaelklachko?direction=desc&sort=updated . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import time, math\n",
    " \n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if use_cuda:\n",
    "    print ('CUDA is available')\n",
    "#use_cuda=False   #uncomment this if you dont want to use cuda variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RNN on The Complete Sherlock Holmes.\n",
      "\n",
      "\n",
      "File length: 3867934 characters\n",
      "Unique characters: 52\n",
      "\n",
      "Unique characters: ['\\n', ' ', '!', '\"', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "('no of uniq chars', 52)\n"
     ]
    }
   ],
   "source": [
    "printable = string.printable\n",
    " \n",
    "#Input text is available here: https://sherlock-holm.es/stories/plain-text/cano.txt\n",
    "text = open('../../../data/lab2/sh.txt', 'r').read().lower()\n",
    "\n",
    "\n",
    "\n",
    "## remove non printable chars and other unnecessary punctuations\n",
    "pruned_text = ''\n",
    " \n",
    "for c in text:\n",
    "\tif c in printable and c not in '{}[]&_':\n",
    "\t\tpruned_text += c\n",
    " \n",
    "text = pruned_text\t\t  \n",
    "file_len = len(text)\n",
    "alphabet = sorted(list(set(text)))\n",
    "n_chars = len(alphabet)\n",
    "\n",
    "print \"\\nTraining RNN on The Complete Sherlock Holmes.\\n\"\t\t \n",
    "print \"\\nFile length: {:d} characters\\nUnique characters: {:d}\".format(file_len, n_chars)\n",
    "print \"\\nUnique characters:\", alphabet\t\t \n",
    "print ('no of uniq chars', n_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_since(since):\n",
    "\ts = time.time() - since\n",
    "\tm = math.floor(s / 60)\n",
    "\ts -= m * 60\n",
    "\treturn '%dm %ds' % (m, s)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_chunk():\n",
    "\tstart = random.randint(0, file_len - chunk_len)\n",
    "\tend = start + chunk_len + 1\n",
    "\treturn text[start:end]\n",
    " \n",
    "def chunk_vector(chunk):\n",
    "\tvector = torch.zeros(len(chunk)).long()\n",
    "\tfor i, c in enumerate(chunk):\n",
    "\t\tvector[i] = alphabet.index(c)  #construct ASCII vector for chunk, one number per character\n",
    "\treturn Variable(vector.cuda(), requires_grad=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_training_batch():\n",
    "\tinputs = []\n",
    "\ttargets = []\n",
    "\t#construct list of input vectors (chunk_len):\n",
    "\tfor b in range(batch_size):    \n",
    "\t\tchunk = random_chunk()\n",
    "\t\tinp = chunk_vector(chunk[:-1])\n",
    "\t\ttarget = chunk_vector(chunk[1:])\n",
    "\t\tinputs.append(inp)\n",
    "\t\ttargets.append(target)\n",
    "\t#construct batches from lists (chunk_len, batch_size):\n",
    "\t#need .view to handle batch_size=1\n",
    "\t#need .contiguous to allow .view later\n",
    "\tinp = torch.cat(inputs, 0).view(batch_size, chunk_len).t().contiguous()\n",
    "\ttarget = torch.cat(targets, 0).view(batch_size, chunk_len).t().contiguous()\n",
    "\treturn inp, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\tdef __init__(self, input_size, hidden_size, output_size, n_layers):\n",
    "\t\tsuper(RNN, self).__init__()\n",
    "\t\t \n",
    "\t\tself.input_size = input_size\n",
    "\t\tself.hidden_size = hidden_size\n",
    "\t\tself.output_size = output_size\n",
    "\t\tself.n_layers = n_layers \n",
    "\t\tself.batch_size = batch_size\n",
    "\t\t \n",
    "\t\tself.encoder = nn.Embedding(input_size, hidden_size) #first arg is dictionary size\n",
    "\t\tself.GRU = nn.GRU(hidden_size, hidden_size, n_layers)  #(input_size, hidden_size, n_layers)\n",
    "\t\tself.decoder = nn.Linear(hidden_size, output_size)\n",
    "\t\t \n",
    "\tdef forward(self, input, hidden, batch_size):\n",
    "\n",
    "\t\tinput = self.encoder(input.view(batch_size, seq_len)) \n",
    "\t\t#need to reshape Input to (seq_len, batch, hidden_size)\n",
    "\t\tinput = input.permute(1, 0, 2)\n",
    "\n",
    "\t\toutput, hidden = self.GRU(input, hidden) \n",
    "\n",
    "\t\toutput = self.decoder(output.view(batch_size, hidden_size))  \n",
    "\t\t#now the output is (batch_size, output_size)\n",
    "\t\treturn output, hidden\n",
    "\tdef init_hidden(self, batch_size):\n",
    "\t\t#Hidden (num_layers * num_directions, batch, hidden_size), num_directions = 2 for BiRNN\n",
    "\t\treturn Variable(torch.randn(self.n_layers, batch_size, self.hidden_size).cuda())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model parameters:\n",
      "\n",
      "n_batches: 800\n",
      "batch_size: 64\n",
      "chunk_len: 128\n",
      "hidden_size: 256\n",
      "n_layers: 2\n",
      "LR: 0.0050\n",
      "\n",
      "\n",
      "Random chunk of text:\n",
      "\n",
      "nally,\n",
      "     remarkably quick-witted, for this whole ingenious story is of his\n",
      "     concoction. yes, watson, we have come upon the \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nTake input, target pairs of chunks (target is shifted forward by a single character)\\nconvert them into chunk vectors\\nfor each char pair (i, t) in chunk vectors (input, target), create embeddings with dim = hidden_size\\nfeed input char vectors to GRU model, and compute error = output - target\\nupdate weights after going through all chars in the chunk\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 1\t\t   #each character is encoded as a single integer\n",
    "chunk_len = 128    #number of characters in a single text sample\n",
    "batch_size = 64   #number of text samples in a batch\n",
    "n_batches =800   #size of training dataset (total number of batches)\n",
    "hidden_size = 256  #width of model\n",
    "n_layers = 2\t  #depth of model\n",
    "LR = 0.005\t\t   #learning rate\n",
    " \n",
    "net = RNN(n_chars, hidden_size, n_chars, n_layers).cuda()\n",
    "#net = RNN(n_chars, hidden_size, n_chars, n_layers)\n",
    "optim = torch.optim.Adam(net.parameters(), LR)\n",
    "cost = nn.CrossEntropyLoss().cuda()  \n",
    " \n",
    "print \"\\nModel parameters:\\n\"\n",
    "print \"n_batches: {:d}\\nbatch_size: {:d}\\nchunk_len: {:d}\\nhidden_size: {:d}\\nn_layers: {:d}\\nLR: {:.4f}\\n\".format(n_batches, batch_size, chunk_len, hidden_size, n_layers, LR)\n",
    "print \"\\nRandom chunk of text:\\n\\n\", random_chunk(), '\\n'\n",
    "\t \n",
    "\"\"\"\n",
    "Take input, target pairs of chunks (target is shifted forward by a single character)\n",
    "convert them into chunk vectors\n",
    "for each char pair (i, t) in chunk vectors (input, target), create embeddings with dim = hidden_size\n",
    "feed input char vectors to GRU model, and compute error = output - target\n",
    "update weights after going through all chars in the chunk\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(prime_str = 'A', predict_len = 100, temp = 0.8, batch_size = 1):\n",
    "\thidden = net.init_hidden(batch_size) \n",
    "\tprime_input = chunk_vector(prime_str)\n",
    "\tpredicted = prime_str\n",
    "\t \n",
    "\tfor i in range(len(prime_str)-1):\n",
    "\t\t_, hidden = net(prime_input[i], hidden, batch_size)\n",
    "\t  \n",
    "\tinp = prime_input[-1]\n",
    "\t \n",
    "\tfor i in range(predict_len):\n",
    "\t\toutput, hidden = net(inp, hidden, batch_size)\n",
    "\t\toutput_dist = output.data.view(-1).div(temp).exp()\t\n",
    "\t\ttop_i = torch.multinomial(output_dist, 1)[0]\n",
    "\t\t \n",
    "\t\tpredicted_char = alphabet[top_i]\n",
    "\t\tpredicted +=  predicted_char\n",
    "\t\tinp = chunk_vector(predicted_char)\n",
    " \n",
    "\treturn predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size '[64 x 128]' is invalid for input of with 8191 elements at /OCRData/minesh.mathew/pytorch-0.1.12/torch/lib/TH/THStorage.c:59",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d49f8112518c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                 \u001b[0mtraining_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_training_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-cf81800c5b74>\u001b[0m in \u001b[0;36mrandom_training_batch\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m#need .view to handle batch_size=1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m#need .contiguous to allow .view later\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/users/minesh.mathew/.local/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mview\u001b[1;34m(self, *sizes)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0msizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mView\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mview_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/users/minesh.mathew/.local/lib/python2.7/site-packages/torch/autograd/_functions/tensor.pyc\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmark_shared_storage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size '[64 x 128]' is invalid for input of with 8191 elements at /OCRData/minesh.mathew/pytorch-0.1.12/torch/lib/TH/THStorage.c:59"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for iter in range(0,10):\n",
    "\ttraining_set = []\n",
    " \n",
    "\tfor i in range(n_batches):\n",
    "\t\ttraining_set.append((random_training_batch()))\n",
    " \n",
    "\ti = 0\t\n",
    "\tfor inp, target in training_set:\n",
    "\t\t#re-init hidden outputs, zero grads, zero loss:\n",
    "\t\thidden = net.init_hidden(batch_size)\n",
    "\t\tnet.zero_grad()\n",
    "\t\tloss = 0\t   \n",
    "\t\t#for each char in a chunk:\n",
    "\t\t#compute output, error, loss:\n",
    "\t\tcount=0\n",
    "\t\tfor c, t in zip(inp, target):\n",
    "\t\t\t#print( 'size of c')\n",
    "\t\t\t#print(c.size())\n",
    "\t\t\tcount=count+1\n",
    "\t\t\toutput, hidden = net(c, hidden, batch_size)\n",
    "\t\t\tloss += cost(output, t)\n",
    "\t\t#calculate gradients, update weights:\n",
    "\t\t#print('count was')\n",
    "\t\t#print (count)\n",
    "\t\tloss.backward()\n",
    "\t\toptim.step()\n",
    " \n",
    "\t\tif i % 100 == 0:\n",
    "\t\t\tprint \"\\n\\nSample output:\\n\"\n",
    "\t\t\tprint evaluate('you are', 100, 0.8), '\\n'\n",
    "\t\t\tprint('[%s (%d / %d) loss: %.4f]' % (time_since(start), i, n_batches, loss.data[0] / chunk_len))\n",
    " \n",
    "\t\ti += 1\n",
    "\t#print('i is')\n",
    "\t\n",
    "\t#print (i)\n",
    "\tprint ( 'completed iteration no.=', iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
