{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Training an OCR using RNN + CTC on Synthetic Images ##\n",
    "- Training images are rendered on the fly\n",
    "- Images are resized to  fixed width , though we can have variying widths since RNN can handle variable length sequences\n",
    "- A word image's each column is treated as a timestep. so inputdim= height of the word image and seqlen= width of the image\n",
    "- CTC loss is used\n",
    "- Unidirectional RNN itself gives good results for English OCR. You can change the net to bidirectional by just changina a flag in the recurrent layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Use a BRNN + CTC to recognize given word image \n",
    "# Network is trained on images rendered using PIL \n",
    "# ============================================================================\n",
    "# for ML Summer School 2017 at IIIT - HYD\n",
    "# Authors -minesh\n",
    "# Do not share this code or the associated exercises anywhere\n",
    "# we might be using the same code/ exercies for our future schools/ events\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "from PIL import Image, ImageFont, ImageDraw, ImageEnhance\n",
    "import numpy as np\n",
    "import time,math\n",
    "from time import sleep\n",
    "import random\n",
    "import sys,codecs,glob \n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from warpctc_pytorch import CTCLoss\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "random.seed(0)\n",
    "# TODO - MAKE SURE CTC IS INSTALLED IN ALL MACHINES\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if use_cuda:\n",
    "    print ('CUDA is available')\n",
    "#use_cuda=False   #uncomment this if you dont want to use cuda variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all word images are resized to a height of 32 pixels\n",
    "imHeight=32 \n",
    "\"\"\"\n",
    "image width is also set a fixed size\n",
    "YES. Though RNNS can handle variable length sequences we resize them to fixed width\n",
    "This is for the ease of batch learning\n",
    "And it doesnt seem to affect the performance much atleast in our case\n",
    "\n",
    "Pytorch provides a packed array API incase you want to have variable length sequences within a batch\n",
    "see the discussion here\n",
    "https://discuss.pytorch.org/t/simple-working-example-how-to-use-packing-for-variable-length-sequence-inputs-for-rnn/2120/8\n",
    "\n",
    "\"\"\"\n",
    "#imWidth=100\n",
    "imWidth=15\n",
    "#65 google fonts are used\n",
    "fontsList=glob.glob('../../../data/lab2/googleFonts/'+'*.ttf')\n",
    "#lexicon has 90k words\n",
    "vocabFile=codecs.open('../../../data/lab2/lexicon.txt','r')\n",
    "words = vocabFile.read().split()\n",
    "vocabSize=len(words)\n",
    "fontSizeOptions={'16','20','24','28','30','32','36','38'}\n",
    "\n",
    "alphabet='0123456789abcdefghijklmnopqrstuvwxyz-'\n",
    "#alphabet=\"(3)-\"\n",
    "dict={}\n",
    "for i, char in enumerate(alphabet):\n",
    "\tdict[char] = i + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_since(since):\n",
    "\ts = time.time() - since\n",
    "\tm = math.floor(s / 60)\n",
    "\ts -= m * 60\n",
    "\treturn '%dm %ds' % (m, s)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Str2Labels(text):\n",
    "\tglobal dict\n",
    "\ttext = [dict[char.lower()] for char in text]\n",
    "\t#print (text)\n",
    "\tlength=len(text)\n",
    "\treturn text, length\n",
    "#StrtoLabels(\"0-1\")\n",
    "\n",
    "def Labels2Str(predictedLabelSequences):\n",
    "    bz=predictedLabelSequences.size(0)\n",
    "    predictedRawStrings=[]\n",
    "    predictedStrings=[]\n",
    "    for i in range(0,bz):\n",
    "        predictedRawString=\"\"\n",
    "        predictedString=\"\"\n",
    "        predictedLabelSeq=predictedLabelSequences.data[i,:]\n",
    "        prevId=1000 #just a large value which is not in the index \n",
    "        character=\"\"\n",
    "        character_raw=\"\"\n",
    "        for j in range (0, predictedLabelSeq.size(0)):\n",
    "            idx=predictedLabelSeq[j]\n",
    "            if (prevId != 1000 or prevId!=idx) :\n",
    "                if prevId!=idx:\n",
    "                    if idx==0:\n",
    "                        character_raw=\"~\"\n",
    "                        character=\"\"\n",
    "                    else:\n",
    "                        character_raw=alphabet[idx-1]\n",
    "                        character=alphabet[idx-1]\n",
    "                else:\n",
    "                    character_raw=\"~\"\n",
    "                    character=\"\"\n",
    "                prevId=idx\n",
    "            else:\n",
    "                character=\"\"\n",
    "                if idx==0:\n",
    "                    character_raw=\"~\"\n",
    "                else:\n",
    "                    character_raw=alphabet[idx-1]\n",
    "                    \n",
    "                    \n",
    "\n",
    "            \n",
    "            predictedString+=character\n",
    "            predictedRawString+=character_raw\n",
    "        predictedRawStrings.append(predictedRawString)\n",
    "        predictedStrings.append(predictedString)\n",
    "        \n",
    "    return predictedRawStrings, predictedStrings\n",
    "\n",
    "\n",
    "\n",
    "def image2tensor(im):\n",
    "\n",
    "    (width, height) = im.size\n",
    "    greyscale_map = list(im.getdata())\n",
    "    greyscale_map = np.array(greyscale_map, dtype = np.uint8)\n",
    "    greyscale_map=greyscale_map.astype(float)\n",
    "    greyscale_map = torch.from_numpy(greyscale_map.reshape((height, width))).float()/255.0\n",
    "    return greyscale_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetBatch ( batchOfWords,singleFont ):\n",
    "    \"\"\"\n",
    "    Renders a batch of word images and returns the images along with the corresponding GTs\n",
    "    Uses PIL to render word images\n",
    "    font is randomly picked from a set of freely available google fonts\n",
    "    word is picked from a vocabulary of English words\n",
    "\n",
    "    \"\"\"\n",
    "    wordImages=[]\n",
    "    labelSequences=[]\n",
    "    labelSeqLengths=[]\n",
    "\n",
    "    for  i,text in enumerate (batchOfWords):\n",
    "        wordText=text\n",
    "        if singleFont==1:\n",
    "            fontName=fontsList[0]\n",
    "            fontSize='26'\n",
    "        else:\n",
    "            fontName=random.sample(fontsList,1)[0]\n",
    "            fontSize=random.sample(fontSizeOptions,1)[0] \n",
    "        imageFont = ImageFont.truetype(fontName,int(fontSize))\n",
    "        textSize=imageFont.getsize(wordText)\n",
    "        img=Image.new(\"L\", textSize,(255))\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        draw.text((0, 0),wordText,(0),font=imageFont)\n",
    "        img=img.resize((imWidth,imHeight), Image.ANTIALIAS)\n",
    "        #img.save(text+'.jpeg')\n",
    "\n",
    "        imgTensor=image2tensor(img)\n",
    "        imgTensor=imgTensor.unsqueeze(0) # at 0 a new dimenion is added\n",
    "\n",
    "        wordImages.append(imgTensor)\n",
    "\n",
    "        labelSeq,l=Str2Labels(wordText)\n",
    "        labelSequences+=labelSeq\n",
    "        labelSeqLengths.append(l)\n",
    "    batchImageTensor=torch.cat(wordImages,0) #now all the image tensors are combined ( we  did the unsqueeze eariler for this cat)  \n",
    "    batchImageTensor=torch.transpose(batchImageTensor,1,2)\n",
    "    labelSequencesTensor=torch.IntTensor(labelSequences)\n",
    "    labelSeqLengthsTensor=torch.IntTensor(labelSeqLengths)\n",
    "    return batchImageTensor, labelSequencesTensor, labelSeqLengthsTensor\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# minesh TODO split blstm into a separate class ?\n",
    "\n",
    "class rnnocr (nn.Module):\n",
    "    def __init__(self, inputDim, hiddenDim, outputDim,  numLayers, numDirections):\n",
    "        super(rnnocr, self).__init__()\n",
    "        self.inputDim=inputDim\n",
    "        self.hiddenDim=hiddenDim\n",
    "        self.outputDim=outputDim\n",
    "        self.numLayers=numLayers\n",
    "        self.numDirections=numDirections\n",
    "        # set bidirectional= true to make the rnn bidirectional\n",
    "        self.blstm1=nn.LSTM(inputDim, hiddenDim,numLayers, bidirectional=False, batch_first=True) # first blstm layer takes the image features as inputs\n",
    "                \n",
    "        self.linearLayer2=nn.Linear(hiddenDim, outputDim) # linear layer at the output\n",
    "        self.softmax = nn.Softmax()\n",
    "                \n",
    "    def forward(self, x ):\n",
    "        B,T,D  = x.size(0), x.size(1), x.size(2)\n",
    "        lstmOut1, _  =self.blstm1(x ) #x has three dimensions batchSize* seqLen * FeatDim\n",
    "        B,T,D  = lstmOut1.size(0), lstmOut1.size(1), lstmOut1.size(2)\n",
    "        lstmOut1=lstmOut1.contiguous()\n",
    "\n",
    "                \n",
    "\n",
    "        outputLayerActivations=self.linearLayer2(lstmOut1.view(B*T,D))\n",
    "        outputSoftMax=self.softmax(outputLayerActivations)\n",
    "        outputLayerActivations= outputLayerActivations.view(B,T,-1).transpose(0,1)\n",
    "        #if use_cuda:\n",
    "        #    outputLayerActivations=outputLayerActivations.cuda()\n",
    "        return outputLayerActivations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def trainNtest(valImages, valLabelSeqs, valLabelSeqlens,singleFont ):\n",
    "    batchSize=50\n",
    "    nHidden=80\n",
    "    nClasses= len(alphabet)\n",
    "    criterion = CTCLoss()\n",
    "    numLayers=2# the 2 BLSTM layers defined seprately without using numLayers option for nn.LSTM\n",
    "    numDirections=2 # 2 since we need to use a bidirectional LSTM\n",
    "    model = rnnocr(imHeight,nHidden,nClasses,numLayers,numDirections)\n",
    "    if use_cuda:\n",
    "        model=model.cuda()\n",
    "        criterion=criterion.cuda()\n",
    "\n",
    "    optimizer=optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    start = time.time()\n",
    "    for iter in range (0,200):\n",
    "        avgTrainCost=0\n",
    "        random.shuffle(words)\n",
    "\n",
    "        for i in range (0,vocabSize-batchSize+1,batchSize):\n",
    "\n",
    "            model.zero_grad()\n",
    "\n",
    "            batchOfWords=words[i:i+batchSize]\n",
    "            images,labelSeqs,labelSeqlens =GetBatch(batchOfWords,singleFont)\n",
    "            images=autograd.Variable(images)\n",
    "            images=images.contiguous()\n",
    "            labelSeqs=autograd.Variable(labelSeqs)\n",
    "            labelSeqlens=autograd.Variable(labelSeqlens)\n",
    "\n",
    "            if use_cuda:\n",
    "                images=images=images.cuda()\n",
    "\n",
    "            outputs=model(images)\n",
    "            outputs=outputs.contiguous()\n",
    "            outputsSize=autograd.Variable(torch.IntTensor([outputs.size(0)] * batchSize))\n",
    "            trainCost = criterion(outputs, labelSeqs, outputsSize, labelSeqlens) / batchSize\n",
    "\n",
    "            avgTrainCost+=trainCost\n",
    "            if i%5000==0:\n",
    "                avgTrainCost=avgTrainCost/(5000/batchSize)\n",
    "                #print ('avgTraincost for last 5000 samples is',avgTrainCost)\n",
    "                avgTrainCost=0\n",
    "                valOutputs=model(valImages)\n",
    "                #print (valOutputs.size()) 100 X nvalsamoles x 37\n",
    "                valOutputs=valOutputs.contiguous()\n",
    "                valOutputsSize=autograd.Variable(torch.IntTensor([valOutputs.size(0)] * len(valWords)))\n",
    "                valCost=criterion(valOutputs, valLabelSeqs, valOutputsSize, valLabelSeqlens) / len(valWords)\n",
    "                print ('validaton Cost is',valCost.data[0])\n",
    "\n",
    "\n",
    "                ### get the actual predictions and compute word error ################\n",
    "                valOutputs_batchFirst=valOutputs.transpose(0,1)\n",
    "                # second output of max() is the argmax along the requuired dimension\n",
    "                _, argMaxActivations= valOutputs_batchFirst.max(2)\n",
    "                #the below tensor each raw is the sequences of labels predicted for each sample in the batch\n",
    "                predictedSeqLabels=argMaxActivations.squeeze(2) #batchSize * seqLen \n",
    "                predictedRawStrings,predictedStrings=Labels2Str(predictedSeqLabels)\n",
    "                for ii in range(0,5):\n",
    "\n",
    "                    print (predictedRawStrings[ii]+\"==>\"+predictedStrings[ii])\n",
    "\n",
    "                    #   print (predictedSeqLabels[0,:].transpose(0,0))\n",
    "                #print(valOutputs_batchFirst[0,0,:])\n",
    "                #print (argMaxActivations[0,:])\n",
    "                print('Time since we began trainiing [%s]' % (time_since(start)))\n",
    "\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            trainCost.backward()\n",
    "            optimizer.step()\n",
    "        #iterString=int(iter)\n",
    "        #torch.save(model.state_dict(), iterString+'.pth')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validaton Cost is 44.1530189514\n",
      "j~~s~~~~~~~~~~~==>js\n",
      "j~~s~~~~~~~~~~~==>js\n",
      "j~s~~~~~~~~~~~~==>js\n",
      "j~~s~~~~~~~~~~~==>js\n",
      "j~~~~s~~~~~~~~~==>js\n",
      "Time since we began trainiing [0m 0s]\n",
      "validaton Cost is 32.2289085388\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 0s]\n",
      "validaton Cost is 10.8872470856\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 0s]\n",
      "validaton Cost is 7.10097503662\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 1s]\n",
      "validaton Cost is 5.93090581894\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 1s]\n",
      "validaton Cost is 5.34590291977\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 1s]\n",
      "validaton Cost is 5.13005685806\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 2s]\n",
      "validaton Cost is 5.13748645782\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 2s]\n",
      "validaton Cost is 4.97002315521\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 2s]\n",
      "validaton Cost is 4.90105342865\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 3s]\n",
      "validaton Cost is 4.88128852844\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 3s]\n",
      "validaton Cost is 4.83655452728\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 3s]\n",
      "validaton Cost is 4.79833126068\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 3s]\n",
      "validaton Cost is 4.80359506607\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 4s]\n",
      "validaton Cost is 4.76990461349\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 4s]\n",
      "validaton Cost is 4.76532745361\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 4s]\n",
      "validaton Cost is 4.76525115967\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 5s]\n",
      "validaton Cost is 4.75984096527\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 5s]\n",
      "validaton Cost is 4.67892551422\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 5s]\n",
      "validaton Cost is 4.78333997726\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 6s]\n",
      "validaton Cost is 4.67812108994\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 6s]\n",
      "validaton Cost is 4.71576786041\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 6s]\n",
      "validaton Cost is 4.73504209518\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 7s]\n",
      "validaton Cost is 4.70320415497\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 7s]\n",
      "validaton Cost is 4.71437644958\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 7s]\n",
      "validaton Cost is 4.67703866959\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 8s]\n",
      "validaton Cost is 4.73014211655\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 8s]\n",
      "validaton Cost is 4.69883680344\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 8s]\n",
      "validaton Cost is 4.7079076767\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 8s]\n",
      "validaton Cost is 4.71639919281\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 9s]\n",
      "validaton Cost is 4.67436647415\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 9s]\n",
      "validaton Cost is 4.66709375381\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 9s]\n",
      "validaton Cost is 4.73400974274\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 10s]\n",
      "validaton Cost is 4.60897541046\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 10s]\n",
      "validaton Cost is 4.67534732819\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 10s]\n",
      "validaton Cost is 4.7520236969\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 11s]\n",
      "validaton Cost is 4.62817239761\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 11s]\n",
      "validaton Cost is 4.68181705475\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 11s]\n",
      "validaton Cost is 4.6617937088\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 12s]\n",
      "validaton Cost is 4.63584280014\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 12s]\n",
      "validaton Cost is 4.7160615921\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 12s]\n",
      "validaton Cost is 4.60912561417\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 13s]\n",
      "validaton Cost is 4.65669441223\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 13s]\n",
      "validaton Cost is 4.68665504456\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 13s]\n",
      "validaton Cost is 4.62883853912\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 13s]\n",
      "validaton Cost is 4.61856746674\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 14s]\n",
      "validaton Cost is 4.65592479706\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 14s]\n",
      "validaton Cost is 4.60211086273\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 14s]\n",
      "validaton Cost is 4.64211177826\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 15s]\n",
      "validaton Cost is 4.59373760223\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 15s]\n",
      "validaton Cost is 4.62185907364\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 15s]\n",
      "validaton Cost is 4.58899736404\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 16s]\n",
      "validaton Cost is 4.62573003769\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 16s]\n",
      "validaton Cost is 4.59070825577\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 16s]\n",
      "validaton Cost is 4.5898809433\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 17s]\n",
      "validaton Cost is 4.58110809326\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 17s]\n",
      "validaton Cost is 4.57771015167\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 17s]\n",
      "validaton Cost is 4.55680465698\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 18s]\n",
      "validaton Cost is 4.58755636215\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 18s]\n",
      "validaton Cost is 4.53925418854\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 18s]\n",
      "validaton Cost is 4.51335191727\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 18s]\n",
      "validaton Cost is 4.54699611664\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 19s]\n",
      "validaton Cost is 4.56404781342\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "b~~~~~~~~~~~~~~==>b\n",
      "Time since we began trainiing [0m 19s]\n",
      "validaton Cost is 4.53938341141\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 19s]\n",
      "validaton Cost is 4.54107761383\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "b~~~~~~~~~~~~~~==>b\n",
      "Time since we began trainiing [0m 20s]\n",
      "validaton Cost is 4.49821186066\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "b~~~~~~~~~~~~~~==>b\n",
      "Time since we began trainiing [0m 20s]\n",
      "validaton Cost is 4.49151468277\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "b~~~~~~~~~~~~~~==>b\n",
      "Time since we began trainiing [0m 20s]\n",
      "validaton Cost is 4.55649995804\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "b~~~~~~~~~~~~~~==>b\n",
      "Time since we began trainiing [0m 21s]\n",
      "validaton Cost is 4.48994731903\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "b~~~~~~~~~~~~~~==>b\n",
      "Time since we began trainiing [0m 21s]\n",
      "validaton Cost is 4.54104423523\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "b~~~~~~~~~~~~~~==>b\n",
      "Time since we began trainiing [0m 21s]\n",
      "validaton Cost is 4.54872655869\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "b~~~~~~~~~~~~~~==>b\n",
      "Time since we began trainiing [0m 22s]\n",
      "validaton Cost is 4.49239015579\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "b~~~~~~~~~~~~~~==>b\n",
      "Time since we began trainiing [0m 22s]\n",
      "validaton Cost is 4.52444934845\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "b~~~~~~~~~~~~~~==>b\n",
      "Time since we began trainiing [0m 22s]\n",
      "validaton Cost is 4.52290487289\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "b~~~~~~~~~~~~~~==>b\n",
      "Time since we began trainiing [0m 23s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-142-f9f3458f9875>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mvalImages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalImages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mtrainNtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalImages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalLabelSeqs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalLabelSeqlens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-141-b43c168f981e>\u001b[0m in \u001b[0;36mtrainNtest\u001b[1;34m(valImages, valLabelSeqs, valLabelSeqlens, singleFont)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mbatchOfWords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabelSeqs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabelSeqlens\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mGetBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatchOfWords\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msingleFont\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0mimages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mimages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-136-172dc93df388>\u001b[0m in \u001b[0;36mGetBatch\u001b[1;34m(batchOfWords, singleFont)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mdraw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageDraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mdraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwordText\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfont\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimageFont\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimWidth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimHeight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mANTIALIAS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;31m#img.save(text+'.jpeg')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/users/minesh.mathew/.local/lib/python2.7/site-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36mresize\u001b[1;34m(self, size, resample)\u001b[0m\n\u001b[0;32m   1557\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGBa'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGBA'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1559\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1561\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNEAREST\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### lets first try to overfit the model to some dummy data ###\n",
    "# we will use only words containing say only three characters a, b and c\n",
    "#and validation also will be words having only those chars\n",
    "\n",
    "vocabFile=codecs.open('../../../data/lab2/small_lexicon.txt','r')\n",
    "words = vocabFile.read().split()\n",
    "vocabSize=len(words)\n",
    "\n",
    "## validation data ##\n",
    "valWords=['cab','bbc','acc','bcc','bac']\n",
    "valImages, valLabelSeqs, valLabelSeqlens=GetBatch(valWords,0)\n",
    "valImages=autograd.Variable(valImages)\n",
    "valImages=valImages.contiguous()\n",
    "\n",
    "    \n",
    "valLabelSeqs=autograd.Variable(valLabelSeqs)\n",
    "#print(valLabelSeqs.data)\n",
    "valLabelSeqlens=autograd.Variable(valLabelSeqlens)\n",
    "if use_cuda:\n",
    "    valImages=valImages.cuda()\n",
    "    \n",
    "trainNtest(valImages, valLabelSeqs, valLabelSeqlens,1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### now lets try on a larger data set, which is rendered from a large vocabulary of 90k words ##\n",
    "vocabFile=codecs.open('../../../data/lab2/lexicon.txt','r')\n",
    "words = vocabFile.read().split()\n",
    "vocabSize=len(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########\n",
    "# Prepare the synthetic validation data for the training\n",
    "##############\n",
    "\n",
    "valWords=['intermittently','hyderabad','golconda','charminar','gachibowli']\n",
    "valImages, valLabelSeqs, valLabelSeqlens=GetBatch(valWords,1)\n",
    "valImages=autograd.Variable(valImages)\n",
    "valImages=valImages.contiguous()\n",
    "\n",
    "    \n",
    "valLabelSeqs=autograd.Variable(valLabelSeqs)\n",
    "#print(valLabelSeqs.data)\n",
    "valLabelSeqlens=autograd.Variable(valLabelSeqlens)\n",
    "if use_cuda:\n",
    "    valImages=valImages.cuda()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validaton Cost is 44.736289978\n",
      "r~~~~~~~~~~~~~~==>r\n",
      "r~~~~~~~~~~~~~~==>r\n",
      "r~~~~~~~~~~~~~~==>r\n",
      "r~~~~~~~~~~~~~~==>r\n",
      "r~~~~~~~~~~~~~~==>r\n",
      "Time since we began trainiing [0m 0s]\n",
      "validaton Cost is 32.8635215759\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 5s]\n",
      "validaton Cost is 32.9022750854\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 9s]\n",
      "validaton Cost is 32.8325080872\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "~~~~~~~~~~~~~~~==>\n",
      "Time since we began trainiing [0m 14s]\n",
      "validaton Cost is 32.7544174194\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "Time since we began trainiing [0m 18s]\n",
      "validaton Cost is 32.5770797729\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "Time since we began trainiing [0m 23s]\n",
      "validaton Cost is 32.6813774109\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "Time since we began trainiing [0m 27s]\n",
      "validaton Cost is 32.4520378113\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "Time since we began trainiing [0m 32s]\n",
      "validaton Cost is 32.3463668823\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "Time since we began trainiing [0m 36s]\n",
      "validaton Cost is 32.2502822876\n",
      "c~~~~~~~~~~~~~~==>c\n",
      "c~~~~~~~~~~~~~~==>c\n",
      "c~~~~~~~~~~~~~~==>c\n",
      "c~~~~~~~~~~~~~~==>c\n",
      "c~~~~~~~~~~~~~~==>c\n",
      "Time since we began trainiing [0m 41s]\n",
      "validaton Cost is 32.7804718018\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "Time since we began trainiing [0m 45s]\n",
      "validaton Cost is 32.1978492737\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "Time since we began trainiing [0m 50s]\n",
      "validaton Cost is 32.4197273254\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "Time since we began trainiing [0m 55s]\n",
      "validaton Cost is 32.0972709656\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "ca~~~~~~~~~~~~~==>ca\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "Time since we began trainiing [0m 59s]\n",
      "validaton Cost is 32.4008522034\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "b~~~~~~~~~~~~~s==>bs\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "p~~~~~~~~~~~~~~==>p\n",
      "Time since we began trainiing [1m 4s]\n",
      "validaton Cost is 32.3374710083\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "be~~~~~~~~~~~~~==>be\n",
      "p~~~~~~~~~~~~~~==>p\n",
      "s~~~~~~~~~~~~~~==>s\n",
      "p~~~~~~~~~~~~~~==>p\n",
      "Time since we began trainiing [1m 8s]\n",
      "validaton Cost is 31.7672519684\n",
      "pa~~~~~~~~~~~~~==>pa\n",
      "ba~~~~~~~~~~~~~==>ba\n",
      "pa~~~~~~~~~~~~~==>pa\n",
      "pa~~~~~~~~~~~~~==>pa\n",
      "pa~~~~~~~~~~~~~==>pa\n",
      "Time since we began trainiing [1m 13s]\n",
      "validaton Cost is 31.8146114349\n",
      "so~~~~~~~~~~~~~==>so\n",
      "bo~~~~~~~~~~~~~==>bo\n",
      "p~~~~~~~~~~~~~~==>p\n",
      "p~~~~~~~~~~~~~~==>p\n",
      "po~~~~~~~~~~~~~==>po\n",
      "Time since we began trainiing [1m 17s]\n",
      "validaton Cost is 31.5234870911\n",
      "pa~~~~~~~~~~~~~==>pa\n",
      "ba~~~~~~~~~~~~~==>ba\n",
      "pa~~~~~~~~~~~~~==>pa\n",
      "pa~~~~~~~~~~~~~==>pa\n",
      "pa~~~~~~~~~~~~~==>pa\n",
      "Time since we began trainiing [1m 20s]\n",
      "validaton Cost is 31.1907691956\n",
      "po~~~~~~~~~~~~g==>pog\n",
      "ba~~~~~~~~~~~~s==>bas\n",
      "po~~~~~~~~~~~~~==>po\n",
      "p~~~~~~~~~~~~~~==>p\n",
      "po~~~~~~~~~~~~~==>po\n",
      "Time since we began trainiing [1m 25s]\n",
      "validaton Cost is 30.8979129791\n",
      "d~~~~~~~~~~~~~y==>dy\n",
      "b~~~~~~~~~i~~~y==>biy\n",
      "d~~~~~~~~~~~~~~==>d\n",
      "s~~~~~~~~~~~~~s==>ss\n",
      "b~~~~~~~~~~~~~~==>b\n",
      "Time since we began trainiing [1m 29s]\n",
      "validaton Cost is 30.1703910828\n",
      "d~~~~~~~~~~~~~g==>dg\n",
      "b~~~~~~~~~i~~~d==>bid\n",
      "p~~~~~~~~~~~~~~==>p\n",
      "p~~~~~~~~~~~~~~==>p\n",
      "p~~~~~~~~~~~~~~==>p\n",
      "Time since we began trainiing [1m 34s]\n",
      "validaton Cost is 29.7938289642\n",
      "d~~~~~~~~~~~~ly==>dly\n",
      "b~~~~~~~~~i~~~d==>bid\n",
      "d~~~~~~~~~~~~~~==>d\n",
      "p~~~~~~~~~~~~~~==>p\n",
      "b~~~~~~~~~~~~~~==>b\n",
      "Time since we began trainiing [1m 38s]\n",
      "validaton Cost is 29.2639961243\n",
      "i~~~~~~~~~~~i~~==>ii\n",
      "b~~~~~~~~~i~~~d==>bid\n",
      "d~~~~~~~~~~~~~~==>d\n",
      "p~~~~~~~~~~~~~~==>p\n",
      "b~~~~~~~~~~~~~~==>b\n",
      "Time since we began trainiing [1m 43s]\n",
      "validaton Cost is 29.1696624756\n",
      "d~~~~~~~i~~~ily==>diily\n",
      "b~~~~~~~~~i~~~d==>bid\n",
      "d~~~~~~~~~~~i~~==>di\n",
      "~~~~~~~~~~~~~~~==>\n",
      "d~~~~~~~~~~i~~~==>di\n",
      "Time since we began trainiing [1m 47s]\n",
      "validaton Cost is 29.0358943939\n",
      "i~~~~~~~~~~~~ly==>ily\n",
      "b~~~~~~~~~i~~sd==>bisd\n",
      "d~~~~~~~~~~~l~~==>dl\n",
      "~~~~~~~~~~~~~~~==>\n",
      "i~~~~~~~~~~~~~s==>is\n",
      "Time since we began trainiing [1m 52s]\n",
      "validaton Cost is 28.7811336517\n",
      "t~~~~~~~i~~~~ly==>tily\n",
      "b~~~~~~~~~i~~sd==>bisd\n",
      "t~~~~~~~~~~~l~~==>tl\n",
      "p~~~~~~~~~~~~~~==>p\n",
      "b~~~~i~i~~i~~~s==>biiis\n",
      "Time since we began trainiing [1m 56s]\n",
      "validaton Cost is 28.7591972351\n",
      "t~~~~~~~i~~~~ly==>tily\n",
      "b~~~~~~~~~i~~~d==>bid\n",
      "d~~~~~~~~~~~l~~==>dl\n",
      "~~~~~~~~~~~~~~~==>\n",
      "i~~~~i~i~~i~~~s==>iiiis\n",
      "Time since we began trainiing [2m 1s]\n",
      "validaton Cost is 29.0136451721\n",
      "t~~~~~~~i~~~ily==>tiily\n",
      "b~~~~~~~~~i~~sd==>bisd\n",
      "d~~~~~~~~~~~l~~==>dl\n",
      "p~~~~~~~~~~~~~~==>p\n",
      "b~~~~i~l~~~~~~s==>bils\n",
      "Time since we began trainiing [2m 5s]\n",
      "validaton Cost is 28.5440616608\n",
      "t~~~~~~~i~~~ily==>tiily\n",
      "f~~~~~~~~~i~~~d==>fid\n",
      "d~~~~~~~~~~~l~~==>dl\n",
      "~~~~~~~~~~~~~~~==>\n",
      "i~~~~~~l~~~~~~~==>il\n",
      "Time since we began trainiing [2m 10s]\n",
      "validaton Cost is 28.4896335602\n",
      "t~~~~~~~i~~~tiy==>titiy\n",
      "b~~~~~~~~~i~~~d==>bid\n",
      "t~~~~~~~~~~~l~~==>tl\n",
      "~~~~~~~~~~~~~~~==>\n",
      "b~~~~~~~~~~~~~s==>bs\n",
      "Time since we began trainiing [2m 14s]\n",
      "validaton Cost is 28.2974853516\n",
      "t~~~~~~~i~~~tly==>titly\n",
      "f~~~~~~~~~l~~sd==>flsd\n",
      "d~~~i~~~~~~~l~~==>dil\n",
      "~~~~~~~~~~~~~~~==>\n",
      "b~~~~l~l~~~~~~s==>blls\n",
      "Time since we began trainiing [2m 19s]\n",
      "validaton Cost is 28.145406723\n",
      "t~i~~~~i~~~nily==>tiinily\n",
      "f~~~i~~~~~i~n~d==>fiind\n",
      "t~~~i~~~~i~~l~s==>tiils\n",
      "s~~~~~~~~~~~n~~==>sn\n",
      "t~~~i~~i~~i~~ts==>tiiits\n",
      "Time since we began trainiing [2m 23s]\n",
      "validaton Cost is 28.1933403015\n",
      "t~i~~~~~i~~nily==>tiinily\n",
      "f~~~~~~~~~l~n~d==>flnd\n",
      "t~~~i~~~~~~~l~s==>tils\n",
      "s~~~~~~~~t~~n~~==>stn\n",
      "t~~~~l~i~~i~~ts==>tliits\n",
      "Time since we began trainiing [2m 28s]\n",
      "validaton Cost is 27.7237815857\n",
      "t~~~~~~~i~n~tly==>tintly\n",
      "f~~~~~~~~~l~ned==>flned\n",
      "t~~~i~~~~~~el~s==>tiels\n",
      "p~~~~~~~~~~~~~~==>p\n",
      "i~~~il~l~~i~~ts==>iillits\n",
      "Time since we began trainiing [2m 32s]\n",
      "validaton Cost is 27.9089775085\n",
      "t~i~~~~t~in~tly==>titintly\n",
      "b~~~i~~~~~i~n~d==>biind\n",
      "t~~~i~i~~t~nl~s==>tiitnls\n",
      "m~~~a~r~~t~n~~~==>martn\n",
      "i~~~il~l~~i~t~s==>iillits\n",
      "Time since we began trainiing [2m 37s]\n",
      "validaton Cost is 27.261428833\n",
      "t~i~~~~tlin~tly==>titlintly\n",
      "b~~~~~~~~al~ned==>balned\n",
      "t~~~i~~~~~~el~s==>tiels\n",
      "r~i~a~r~~tie~nr==>riartienr\n",
      "i~~~il~l~~i~ets==>iilliets\n",
      "Time since we began trainiing [2m 40s]\n",
      "validaton Cost is 26.8756160736\n",
      "i~i~~~~t~in~tly==>iitintly\n",
      "f~~~i~~~~al~e~d==>fialed\n",
      "i~~~i~~~~~~el~s==>iiels\n",
      "t~~~a~~~~t~~~n~==>tatn\n",
      "i~~~il~l~~tiets==>iilltiets\n",
      "Time since we began trainiing [2m 44s]\n",
      "validaton Cost is 27.1693172455\n",
      "i~~~~~~~t~ently==>itently\n",
      "f~~~~~e~~~l~e~d==>feled\n",
      "i~~~i~~~~~~ed~s==>iieds\n",
      "m~~~a~~~~~~~~~~==>ma\n",
      "i~~~i~~i~~~~ets==>iiiets\n",
      "Time since we began trainiing [2m 49s]\n",
      "validaton Cost is 26.4555473328\n",
      "t~~~~~~t~in~tly==>ttintly\n",
      "f~~~~~e~~al~e~d==>fealed\n",
      "i~~~i~~~~~~el~s==>iiels\n",
      "s~~~a~~~~~~~~a~==>saa\n",
      "i~~~il~l~~tiets==>iilltiets\n",
      "Time since we began trainiing [2m 53s]\n",
      "validaton Cost is 26.8619804382\n",
      "t~i~r~~t~iently==>tirtiently\n",
      "b~~~i~e~~al~e~d==>biealed\n",
      "t~~i~~r~~i~el~s==>tiriels\n",
      "m~~~~~~~~~~~~~~==>m\n",
      "i~i~~l~l~~i~~ts==>iillits\n",
      "Time since we began trainiing [2m 58s]\n",
      "validaton Cost is 26.4211006165\n",
      "t~i~~~~al~anily==>tialanily\n",
      "b~~~i~e~~al~e~d==>biealed\n",
      "t~~i~~~~~~~el~s==>tiels\n",
      "m~i~a~~~~i~n~a~==>miaina\n",
      "i~i~il~l~~i~ets==>iiilliets\n",
      "Time since we began trainiing [3m 2s]\n",
      "validaton Cost is 25.6930274963\n",
      "t~ie~~~i~~ently==>tieiently\n",
      "b~~~i~e~~al~e~d==>biealed\n",
      "t~~i~~~~~i~el~s==>tiiels\n",
      "m~i~a~~~~~a~~a~==>miaaa\n",
      "i~i~il~l~~i~ets==>iiilliets\n",
      "Time since we began trainiing [3m 7s]\n",
      "validaton Cost is 25.7067222595\n",
      "t~i~r~~t~iently==>tirtiently\n",
      "l~~~i~e~~al~e~d==>liealed\n",
      "i~~~l~i~~t~el~s==>ilitels\n",
      "r~i~a~t~~i~na~~==>riatina\n",
      "i~i~il~l~~i~rts==>iiillirts\n",
      "Time since we began trainiing [3m 12s]\n",
      "validaton Cost is 26.3396186829\n",
      "t~ier~~itiently==>tieritiently\n",
      "b~~~i~e~~al~e~d==>biealed\n",
      "t~~~i~i~~i~el~s==>tiiiels\n",
      "m~~~a~~~~i~n~ae==>mainae\n",
      "i~iril~l~~i~rts==>iirillirts\n",
      "Time since we began trainiing [3m 16s]\n",
      "validaton Cost is 24.381067276\n",
      "p~ie~~~i~ienily==>pieiienily\n",
      "b~~~i~e~~al~o~d==>biealod\n",
      "t~~i~~i~~i~el~s==>tiiiels\n",
      "m~~~a~~~~i~n~ae==>mainae\n",
      "t~~~il~l~~i~ets==>tilliets\n",
      "Time since we began trainiing [3m 21s]\n",
      "validaton Cost is 25.116394043\n",
      "t~ier~~i~iently==>tieriiently\n",
      "b~~~i~e~~al~e~d==>biealed\n",
      "i~~~i~i~~~~el~s==>iiiels\n",
      "t~~~a~r~~i~n~ae==>tarinae\n",
      "i~l~il~l~~i~rts==>ilillirts\n",
      "Time since we began trainiing [3m 25s]\n",
      "validaton Cost is 24.3463306427\n",
      "t~ier~~i~iently==>tieriiently\n",
      "b~~~i~e~~al~e~d==>biealed\n",
      "i~~i~~i~~~~nl~s==>iiinls\n",
      "t~~~a~~~~i~n~a~==>taina\n",
      "i~i~il~l~~i~rt~==>iiillirt\n",
      "Time since we began trainiing [3m 30s]\n",
      "validaton Cost is 25.0288829803\n",
      "t~ier~~itiently==>tieritiently\n",
      "b~~~i~e~~al~e~d==>biealed\n",
      "i~~~l~i~~~~el~s==>iliels\n",
      "t~~~a~r~~i~n~ar==>tarinar\n",
      "i~ir~l~l~~i~r~s==>iirllirs\n",
      "Time since we began trainiing [3m 34s]\n",
      "validaton Cost is 24.9834022522\n",
      "t~~e~~~itiently==>teitiently\n",
      "b~~~i~e~~al~e~d==>biealed\n",
      "d~~i~~i~~t~el~s==>diitels\n",
      "t~~~a~r~~i~n~ar==>tarinar\n",
      "i~iril~l~~tirts==>iirilltirts\n",
      "Time since we began trainiing [3m 39s]\n",
      "validaton Cost is 23.2756156921\n",
      "p~ier~~itiently==>pieritiently\n",
      "b~~~i~e~~al~o~d==>biealod\n",
      "i~~~i~i~~~~nl~s==>iiinls\n",
      "t~~~a~rm~i~n~a~==>tarmina\n",
      "i~iril~l~~i~nts==>iirillints\n",
      "Time since we began trainiing [3m 43s]\n",
      "validaton Cost is 23.2603931427\n",
      "i~ier~~i~iently==>iieriiently\n",
      "l~~~i~e~~al~a~d==>liealad\n",
      "i~~~l~i~~~~~l~d==>ilild\n",
      "t~~~a~~~~i~n~ar==>tainar\n",
      "i~l~il~l~~i~nt~==>ilillint\n",
      "Time since we began trainiing [3m 48s]\n",
      "validaton Cost is 23.0395412445\n",
      "t~ier~~itiently==>tieritiently\n",
      "b~~~i~e~~al~o~d==>biealod\n",
      "t~~~i~i~n~~nl~s==>tiinnls\n",
      "t~~~a~r~~i~n~ae==>tarinae\n",
      "i~iril~l~~i~et~==>iirilliet\n",
      "Time since we began trainiing [3m 52s]\n",
      "validaton Cost is 21.5665359497\n",
      "i~ie~rmitienily==>iiermitienily\n",
      "l~~~i~er~al~a~d==>lieralad\n",
      "i~~~l~i~nt~nl~d==>ilintnld\n",
      "t~~~a~rm~i~n~ar==>tarminar\n",
      "i~iril~d~~i~el~==>iirildiel\n",
      "Time since we began trainiing [3m 57s]\n",
      "validaton Cost is 22.5543937683\n",
      "t~ie~r~itiently==>tieritiently\n",
      "l~~~l~e~~al~o~d==>llealod\n",
      "i~~~l~i~n~~~l~s==>ilinls\n",
      "t~~~a~rm~i~n~ar==>tarminar\n",
      "i~iril~l~~i~ets==>iirilliets\n",
      "Time since we began trainiing [3m 59s]\n",
      "validaton Cost is 22.3792171478\n",
      "i~ie~r~itiently==>iieritiently\n",
      "b~y~i~e~~a~~o~d==>byieaod\n",
      "d~~i~~i~n~~~l~s==>diinls\n",
      "s~~~a~r~~i~n~ae==>sarinae\n",
      "i~iril~l~~i~ets==>iirilliets\n",
      "Time since we began trainiing [4m 4s]\n",
      "validaton Cost is 23.2898674011\n",
      "t~re~nmot~ent~y==>trenmotenty\n",
      "l~~~i~e~~al~e~d==>liealed\n",
      "i~~ri~~~n~~~l~s==>irinls\n",
      "t~~~a~rm~i~n~ar==>tarminar\n",
      "i~iril~d~~eners==>iirildeners\n",
      "Time since we began trainiing [4m 9s]\n",
      "validaton Cost is 21.2160587311\n",
      "i~ier~mitiently==>iiermitiently\n",
      "b~~~l~er~a~~~~d==>blerad\n",
      "i~~il~i~nt~nl~d==>iilintnld\n",
      "t~~~a~rm~i~n~ar==>tarminar\n",
      "i~iril~l~~t~etl==>iirilltetl\n",
      "Time since we began trainiing [4m 13s]\n",
      "validaton Cost is 21.2003746033\n",
      "i~~e~r~it~ently==>ieritently\n",
      "b~~~l~e~~al~o~d==>blealod\n",
      "d~~ri~i~n~~~l~a==>driinla\n",
      "s~~~a~rm~i~n~ar==>sarminar\n",
      "i~iril~l~~t~el~==>iirilltel\n",
      "Time since we began trainiing [4m 18s]\n",
      "validaton Cost is 21.3018398285\n",
      "t~ie~m~itiently==>tiemitiently\n",
      "b~y~i~e~~a~~~~d==>byiead\n",
      "d~~~l~i~n~~~l~d==>dlinld\n",
      "t~~~a~rm~ian~an==>tarmianan\n",
      "i~irl~~l~~in~l~==>iirllinl\n",
      "Time since we began trainiing [4m 22s]\n",
      "validaton Cost is 22.032617569\n",
      "i~ie~rmitienily==>iiermitienily\n",
      "b~~~l~er~al~a~d==>bleralad\n",
      "i~~~l~i~~t~~l~d==>ilitld\n",
      "t~h~anrm~i~n~ar==>thanrminar\n",
      "b~iril~l~~inel~==>birillinel\n",
      "Time since we began trainiing [4m 27s]\n",
      "validaton Cost is 22.0010986328\n",
      "i~ier~mitienily==>iiermitienily\n",
      "b~~~i~e~~a~~~~d==>biead\n",
      "i~~~l~i~n~~~l~a==>ilinla\n",
      "t~h~a~r~~i~n~an==>tharinan\n",
      "i~iril~l~~in~l~==>iirillinl\n",
      "Time since we began trainiing [4m 31s]\n",
      "validaton Cost is 21.4451141357\n",
      "t~re~rmit~enily==>trermitenily\n",
      "b~~~l~e~~a~~~~d==>blead\n",
      "d~~~i~i~n~~~l~a==>diinla\n",
      "t~~~a~r~~i~n~ar==>tarinar\n",
      "b~~ril~d~~t~n~~==>brildtn\n",
      "Time since we began trainiing [4m 36s]\n",
      "validaton Cost is 20.6991672516\n",
      "t~ier~mitienily==>tiermitienily\n",
      "b~y~i~e~~al~~~d==>byieald\n",
      "d~~~l~i~n~~~l~s==>dlinls\n",
      "c~~~a~rm~i~n~an==>carminan\n",
      "i~irl~~l~~n~~~s==>iirllns\n",
      "Time since we began trainiing [4m 40s]\n",
      "validaton Cost is 20.5424346924\n",
      "i~ier~mitiently==>iiermitiently\n",
      "b~y~l~er~a~~a~d==>byleraad\n",
      "i~~~l~i~n~~~l~a==>ilinla\n",
      "t~h~a~rm~i~n~ar==>tharminar\n",
      "i~irl~~l~~tn~l~==>iirlltnl\n",
      "Time since we began trainiing [4m 45s]\n",
      "validaton Cost is 21.0142040253\n",
      "t~ie~tmitiently==>tietmitiently\n",
      "h~y~l~er~a~~a~d==>hyleraad\n",
      "d~~~l~i~n~~~l~a==>dlinla\n",
      "t~h~a~rm~i~n~an==>tharminan\n",
      "b~irl~~l~~tn~l~==>birlltnl\n",
      "Time since we began trainiing [4m 49s]\n",
      "validaton Cost is 20.3582229614\n",
      "t~re~rmitiently==>trermitiently\n",
      "b~~~l~er~a~~~~d==>blerad\n",
      "d~~rl~i~nm~~l~s==>drlinmls\n",
      "t~h~a~rm~i~n~ar==>tharminar\n",
      "d~irl~~d~~n~~ls==>dirldnls\n",
      "Time since we began trainiing [4m 54s]\n",
      "validaton Cost is 19.566860199\n",
      "t~ie~tmitiently==>tietmitiently\n",
      "b~~~l~e~~a~~~~d==>blead\n",
      "i~~~l~i~n~~~d~a==>ilinda\n",
      "t~h~a~rm~i~n~ar==>tharminar\n",
      "i~irl~~l~~tn~ld==>iirlltnld\n",
      "Time since we began trainiing [4m 58s]\n",
      "validaton Cost is 19.3552341461\n",
      "i~ie~nmitienily==>iienmitienily\n",
      "b~y~i~e~~a~~a~d==>byieaad\n",
      "d~~~l~cin~~~l~a==>dlcinla\n",
      "t~h~a~rm~i~n~an==>tharminan\n",
      "i~irl~~d~~n~~ld==>iirldnld\n",
      "Time since we began trainiing [5m 3s]\n",
      "validaton Cost is 19.3132858276\n",
      "t~iertmitiently==>tiertmitiently\n",
      "b~~~l~er~a~~~~d==>blerad\n",
      "d~~~l~i~n~~~l~a==>dlinla\n",
      "t~h~a~rm~i~n~ar==>tharminar\n",
      "b~irl~~b~~in~l~==>birlbinl\n",
      "Time since we began trainiing [5m 7s]\n",
      "validaton Cost is 18.9386329651\n",
      "i~ter~mitiently==>itermitiently\n",
      "b~y~l~er~a~~~~d==>bylerad\n",
      "i~~rl~cin~~~l~a==>irlcinla\n",
      "t~h~a~rm~i~n~an==>tharminan\n",
      "b~irl~~b~~n~~l~==>birlbnl\n",
      "Time since we began trainiing [5m 12s]\n",
      "validaton Cost is 19.3777198792\n",
      "t~ie~m~itienily==>tiemitienily\n",
      "h~~~l~en~a~~a~d==>hlenaad\n",
      "d~~ib~i~n~~~l~a==>dibinla\n",
      "t~h~anm~~i~na~n==>thanminan\n",
      "i~irl~~b~~n~~l~==>iirlbnl\n",
      "Time since we began trainiing [5m 17s]\n",
      "validaton Cost is 19.8029670715\n",
      "t~ie~rmitienily==>tiermitienily\n",
      "h~~~l~er~a~~a~d==>hleraad\n",
      "d~~rl~cin~~~l~a==>drlcinla\n",
      "t~h~a~rm~i~n~an==>tharminan\n",
      "i~irl~~l~~n~el~==>iirllnel\n",
      "Time since we began trainiing [5m 19s]\n",
      "validaton Cost is 18.6583900452\n",
      "t~iertmitiently==>tiertmitiently\n",
      "h~~~l~e~~a~~~~d==>hlead\n",
      "d~~~l~i~n~~~l~a==>dlinla\n",
      "t~h~a~rm~i~n~an==>tharminan\n",
      "b~i~l~~l~~tn~l~==>billtnl\n",
      "Time since we began trainiing [5m 24s]\n",
      "validaton Cost is 19.3745994568\n",
      "i~iertmitiently==>iiertmitiently\n",
      "h~~~b~en~a~~a~d==>hbenaad\n",
      "d~~rb~tintn~l~d==>drbtintnld\n",
      "t~h~anrm~i~na~n==>thanrminan\n",
      "l~irlh~b~~tn~l~==>lirlhbtnl\n",
      "Time since we began trainiing [5m 28s]\n",
      "validaton Cost is 18.0044441223\n",
      "t~ie~m~it~ently==>tiemitently\n",
      "h~~~l~er~a~~a~d==>hleraad\n",
      "d~~~l~c~a~~~d~a==>dlcada\n",
      "t~h~a~rm~i~na~n==>tharminan\n",
      "p~i~lh~l~~tn~l~==>pilhltnl\n",
      "Time since we began trainiing [5m 33s]\n",
      "validaton Cost is 18.0715141296\n",
      "t~re~rmitient~y==>trermitienty\n",
      "h~~yl~er~a~~~~d==>hylerad\n",
      "d~~~l~c~n~~~d~a==>dlcnda\n",
      "c~h~a~rm~i~n~an==>charminan\n",
      "i~ielh~l~~n~~ld==>iielhlnld\n",
      "Time since we began trainiing [5m 38s]\n",
      "validaton Cost is 18.9521408081\n",
      "t~ierm~itiently==>tiermitiently\n",
      "b~~yl~en~a~~a~d==>bylenaad\n",
      "d~~rb~c~n~~~l~a==>drbcnla\n",
      "c~h~anrm~i~na~n==>chanrminan\n",
      "b~ielh~b~~n~~l~==>bielhbnl\n",
      "Time since we began trainiing [5m 42s]\n",
      "validaton Cost is 18.5945072174\n",
      "i~ter~mitiently==>itermitiently\n",
      "h~~~l~er~a~~a~d==>hleraad\n",
      "d~~~l~c~t~~~l~a==>dlctla\n",
      "t~h~anrm~i~na~n==>thanrminan\n",
      "i~iel~~l~~t~~l~==>iielltl\n",
      "Time since we began trainiing [5m 47s]\n",
      "validaton Cost is 19.2286930084\n",
      "t~ier~mitiently==>tiermitiently\n",
      "b~y~l~er~ab~a~d==>bylerabad\n",
      "d~~~l~c~n~~~l~a==>dlcnla\n",
      "t~h~a~rm~i~n~an==>tharminan\n",
      "d~~el~~b~~n~~l~==>delbnl\n",
      "Time since we began trainiing [5m 51s]\n",
      "validaton Cost is 19.5919456482\n",
      "t~ie~rmit~enily==>tiermitenily\n",
      "h~~yl~e~~ab~a~d==>hyleabad\n",
      "d~~~l~c~a~~~l~a==>dlcala\n",
      "t~h~a~rm~i~na~n==>tharminan\n",
      "b~~el~~l~~onel~==>bellonel\n",
      "Time since we began trainiing [5m 56s]\n",
      "validaton Cost is 19.1233825684\n",
      "t~ie~m~it~enily==>tiemitenily\n",
      "b~~yl~e~~a~~a~d==>byleaad\n",
      "d~~~l~c~~m~~l~a==>dlcmla\n",
      "t~h~a~rm~i~~a~n==>tharmian\n",
      "b~ielh~b~~n~~l~==>bielhbnl\n",
      "Time since we began trainiing [6m 0s]\n",
      "validaton Cost is 18.2085227966\n",
      "t~ie~rmit~ently==>tiermitently\n",
      "b~y~l~e~~a~~a~d==>byleaad\n",
      "d~~~l~c~a~~~d~a==>dlcada\n",
      "c~h~a~rm~i~~a~n==>charmian\n",
      "d~iel~~d~~onel~==>dieldonel\n",
      "Time since we began trainiing [6m 5s]\n",
      "validaton Cost is 18.6810932159\n",
      "t~ier~mitiently==>tiermitiently\n",
      "h~~yl~er~a~~a~d==>hyleraad\n",
      "d~~rl~t~t~~~l~a==>drlttla\n",
      "c~h~a~rm~i~na~n==>charminan\n",
      "b~~el~~b~~n~~l~==>belbnl\n",
      "Time since we began trainiing [6m 9s]\n",
      "validaton Cost is 17.932056427\n",
      "t~iertmitiently==>tiertmitiently\n",
      "h~y~l~er~ab~~~d==>hylerabd\n",
      "d~~~l~c~tm~~l~a==>dlctmla\n",
      "c~h~a~rm~i~n~an==>charminan\n",
      "i~~el~~l~~tn~l~==>ielltnl\n",
      "Time since we began trainiing [6m 14s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-c657b956b2d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainNtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalImages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalLabelSeqs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalLabelSeqlens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# set the last argument in above function call to 1 if it trains more than 10 minutes to converge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# if the last argument is 1 then only one font will be used in rendering images and so it ll converge fast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-141-b43c168f981e>\u001b[0m in \u001b[0;36mtrainNtest\u001b[1;34m(valImages, valLabelSeqs, valLabelSeqlens, singleFont)\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0moutputsSize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIntTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/users/minesh.mathew/.local/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-140-81bc911380f5>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mD\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mlstmOut1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m  \u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblstm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;31m#x has three dimensions batchSize* seqLen * FeatDim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mD\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mlstmOut1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlstmOut1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlstmOut1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mlstmOut1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlstmOut1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/users/minesh.mathew/.local/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/users/minesh.mathew/.local/lib/python2.7/site-packages/torch/nn/modules/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0mdropout_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         )\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/users/minesh.mathew/.local/lib/python2.7/site-packages/torch/nn/_functions/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[1;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutogradRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/users/minesh.mathew/.local/lib/python2.7/site-packages/torch/autograd/function.pyc\u001b[0m in \u001b[0;36m_do_forward\u001b[1;34m(self, *input)\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nested_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[0mflat_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_iter_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m         \u001b[0mflat_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNestedIOFunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mflat_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m         \u001b[0mnested_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0mnested_variables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/users/minesh.mathew/.local/lib/python2.7/site-packages/torch/autograd/function.pyc\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[0mnested_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_map_variable_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_extended\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnested_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nested_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/users/minesh.mathew/.local/lib/python2.7/site-packages/torch/nn/_functions/rnn.pyc\u001b[0m in \u001b[0;36mforward_extended\u001b[1;34m(self, input, weight, hx)\u001b[0m\n\u001b[0;32m    283\u001b[0m             \u001b[0mhy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m         \u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/users/minesh.mathew/.local/lib/python2.7/site-packages/torch/backends/cudnn/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[1;34m(fn, input, hx, weight, output, hy)\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_descs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescriptor_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m             \u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_descs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescriptor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m             \u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_descs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescriptor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhx_desc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescriptor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/users/minesh.mathew/.local/lib/python2.7/site-packages/torch/backends/cudnn/__init__.pyc\u001b[0m in \u001b[0;36mdescriptor\u001b[1;34m(tensor, N)\u001b[0m\n\u001b[0;32m    298\u001b[0m     \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadded_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mN\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m         \u001b[0mdescriptor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTensorDescriptorArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m         \u001b[0mdescriptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/users/minesh.mathew/.local/lib/python2.7/site-packages/torch/backends/cudnn/__init__.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mTensorDescriptorArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mptrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_void_p\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mptrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msizeof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainNtest(valImages, valLabelSeqs, valLabelSeqlens,0)\n",
    "# set the last argument in above function call to 1 if it trains more than 10 minutes to converge\n",
    "# if the last argument is 1 then only one font will be used in rendering images and so it ll converge fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
