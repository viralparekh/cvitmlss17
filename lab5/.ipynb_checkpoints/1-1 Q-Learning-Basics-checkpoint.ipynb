{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning Basics\n",
    "\n",
    "TO-DO explain about basics of q learning, giving equations and posing it as a value iteration method. Also talk about the environment (open-ai gym, frozen lake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Q-Table Algorithm\n",
    "\n",
    "Talk about the formulation of problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-12 12:19:40,498] Making new env: FrozenLake-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialize table with all zeros\n",
    "Q = np.zeros([env.observation_space.n,env.action_space.n])\n",
    "# Set learning parameters\n",
    "lr = .8\n",
    "gamma = .95\n",
    "num_episodes = 2000\n",
    "#create lists to contain total rewards and steps per episode\n",
    "#jList = []\n",
    "rList = []\n",
    "for i in range(num_episodes):\n",
    "    #Reset environment and get first new observation\n",
    "    s = env.reset()\n",
    "    rAll = 0\n",
    "    d = False\n",
    "    j = 0\n",
    "    #The Q-Table learning algorithm\n",
    "    while j < 99:\n",
    "        j+=1\n",
    "        #Choose an action by greedily (with noise) picking from Q table\n",
    "        a = np.argmax(Q[s,:] + np.random.randn(1,env.action_space.n)*(1./(i+1)))\n",
    "        #Get new state and reward from environment\n",
    "        s1,r,d,_ = env.step(a)\n",
    "        #Update Q-Table with new knowledge\n",
    "        Q[s,a] = Q[s,a] + lr*(r + gamma*np.max(Q[s1,:]) - Q[s,a])\n",
    "        rAll += r\n",
    "        s = s1\n",
    "        if d == True:\n",
    "            break\n",
    "    #jList.append(j)\n",
    "    rList.append(rAll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score over time: 0.4615\n"
     ]
    }
   ],
   "source": [
    "print (\"Score over time: \" +  str(sum(rList)/num_episodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Q-Table Values\n",
      "[[  2.90494219e-01   6.86375101e-03   9.10124731e-03   6.13997383e-03]\n",
      " [  3.83769284e-05   1.03832229e-03   2.26072253e-05   1.94100378e-01]\n",
      " [  3.34558598e-03   3.52705112e-03   1.59524467e-03   1.59873714e-01]\n",
      " [  2.03530694e-04   9.05915290e-04   7.58636357e-06   9.42525790e-02]\n",
      " [  4.24152967e-01   2.45176953e-03   2.45259936e-04   1.07198729e-03]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  2.29015752e-05   2.71350564e-05   2.82835646e-03   3.55706505e-04]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  8.43917316e-04   6.11974374e-04   8.42985341e-04   2.93670082e-01]\n",
      " [  1.40948987e-03   5.63950912e-01   1.55203537e-03   7.10611095e-04]\n",
      " [  1.42239083e-01   2.09617390e-04   4.33896986e-04   1.91614998e-04]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  7.17053776e-04   2.28902220e-04   9.22581934e-01   4.80108773e-04]\n",
      " [  0.00000000e+00   0.00000000e+00   7.23387110e-01   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Final Q-Table Values\")\n",
    "print (Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Q-Network - Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-12 12:24:49,603] Making new env: FrozenLake-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#These lines establish the feed-forward part of the network used to choose actions\n",
    "inputs1 = tf.placeholder(shape=[1,16],dtype=tf.float32)\n",
    "W = tf.Variable(tf.random_uniform([16,4],0,0.01))\n",
    "Qout = tf.matmul(inputs1,W)\n",
    "predict = tf.argmax(Qout,1)\n",
    "\n",
    "#Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "nextQ = tf.placeholder(shape=[1,4],dtype=tf.float32)\n",
    "loss = tf.reduce_sum(tf.square(nextQ - Qout))\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "updateModel = trainer.minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /users/aditya.a/Libraries/miniconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-12 12:26:04,016] From /users/aditya.a/Libraries/miniconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of succesful episodes: 0.154%\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Set learning parameters\n",
    "y = .99\n",
    "e = 0.1\n",
    "num_episodes = 2000\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_episodes):\n",
    "        #Reset environment and get first new observation\n",
    "        s = env.reset()\n",
    "        rAll = 0\n",
    "        d = False\n",
    "        j = 0\n",
    "        #The Q-Network\n",
    "        while j < 99:\n",
    "            j+=1\n",
    "            #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            a,allQ = sess.run([predict,Qout],feed_dict={inputs1:np.identity(16)[s:s+1]})\n",
    "            if np.random.rand(1) < e:\n",
    "                a[0] = env.action_space.sample()\n",
    "            #Get new state and reward from environment\n",
    "            s1,r,d,_ = env.step(a[0])\n",
    "            #Obtain the Q' values by feeding the new state through our network\n",
    "            Q1 = sess.run(Qout,feed_dict={inputs1:np.identity(16)[s1:s1+1]})\n",
    "            #Obtain maxQ' and set our target value for chosen action.\n",
    "            maxQ1 = np.max(Q1)\n",
    "            targetQ = allQ\n",
    "            targetQ[0,a[0]] = r + y*maxQ1\n",
    "            #Train our network using target and predicted Q values\n",
    "            _,W1 = sess.run([updateModel,W],feed_dict={inputs1:np.identity(16)[s:s+1],nextQ:targetQ})\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            if d == True:\n",
    "                #Reduce chance of random action as we train the model.\n",
    "                e = 1./((i/50) + 10)\n",
    "                break\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "print (\"Percent of succesful episodes: \" + str(sum(rList)/num_episodes) + \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdeac081c50>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdead3c3780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Q-Network - PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-12 12:32:49,329] Making new env: FrozenLake-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we will define a feed forward neural network\n",
    "class Q_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        l1 = nn.Linear(16,4)\n",
    "    \n",
    "    def forward(x):\n",
    "        out = f.tanh(l1(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Q-Net\n",
    "\n",
    "# initialize the net\n",
    "q_net = Q_Net()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# set hyper-parameter value\n",
    "gamma = 0.99\n",
    "e = 0.1\n",
    "\n",
    "# create list to contain total rewards and steps per episode\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
