{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import gym.spaces\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "\n",
    "from utils.replay_buffer import ReplayBuffer\n",
    "from utils.gym import get_env, get_wrapper_by_name\n",
    "from utils.schedule import ConstantSchedule, PiecewiseSchedule, LinearSchedule\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.99\n",
    "REPLAY_BUFFER_SIZE = 1000000\n",
    "LEARNING_STARTS = 50000\n",
    "LEARNING_FREQ = 4\n",
    "FRAME_HISTORY_LEN = 4\n",
    "TARGET_UPDATE_FREQ = 10000\n",
    "LEARNING_RATE = 0.00025\n",
    "ALPHA = 0.95\n",
    "EPS = 0.01\n",
    "PONG = 3\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "\n",
    "class Variable(autograd.Variable):\n",
    "    def __init__(self, data, *args, **kwargs):\n",
    "        if USE_CUDA:\n",
    "            data = data.cuda()\n",
    "        super(Variable, self).__init__(data, *args, **kwargs)\n",
    "\n",
    "\"\"\"\n",
    "    OptimizerSpec containing following attributes\n",
    "        constructor: The optimizer constructor ex: RMSprop\n",
    "        kwargs: {Dict} arguments for constructing optimizer\n",
    "\"\"\"\n",
    "OptimizerSpec = namedtuple(\"OptimizerSpec\", [\"constructor\", \"kwargs\"])\n",
    "\n",
    "Statistic = {\n",
    "    \"mean_episode_rewards\": [],\n",
    "    \"best_mean_episode_rewards\": []\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Deep Q Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, in_channels=4, num_actions=18):\n",
    "        \"\"\"\n",
    "        Initialize a deep Q-learning network as described in\n",
    "        https://storage.googleapis.com/deepmind-data/assets/papers/DeepMindNature14236Paper.pdf\n",
    "        Arguments:\n",
    "            in_channels: number of channel of input.\n",
    "                i.e The number of most recent frames stacked together as describe in the paper\n",
    "            num_actions: number of action-value to output, one-to-one correspondence to action in game.\n",
    "        \"\"\"\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "        self.fc4 = nn.Linear(7 * 7 * 64, 512)\n",
    "        self.fc5 = nn.Linear(512, num_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.fc4(x.view(x.size(0), -1)))\n",
    "        return self.fc5(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dqn_learing(\n",
    "    env,\n",
    "    q_func,\n",
    "    optimizer_spec,\n",
    "    exploration,\n",
    "    stopping_criterion=None,\n",
    "    replay_buffer_size=1000000,\n",
    "    batch_size=32,\n",
    "    gamma=0.99,\n",
    "    learning_starts=50000,\n",
    "    learning_freq=4,\n",
    "    frame_history_len=4,\n",
    "    target_update_freq=10000\n",
    "    ):\n",
    "\n",
    "    \"\"\"Run Deep Q-learning algorithm.\n",
    "\n",
    "    You can specify your own convnet using q_func.\n",
    "\n",
    "    All schedules are w.r.t. total number of steps taken in the environment.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    env: gym.Env\n",
    "        gym environment to train on.\n",
    "    q_func: function\n",
    "        Model to use for computing the q function. It should accept the\n",
    "        following named arguments:\n",
    "            input_channel: int\n",
    "                number of channel of input.\n",
    "            num_actions: int\n",
    "                number of actions\n",
    "    optimizer_spec: OptimizerSpec\n",
    "        Specifying the constructor and kwargs, as well as learning rate schedule\n",
    "        for the optimizer\n",
    "    exploration: Schedule (defined in utils.schedule)\n",
    "        schedule for probability of chosing random action.\n",
    "    stopping_criterion: (env) -> bool\n",
    "        should return true when it's ok for the RL algorithm to stop.\n",
    "        takes in env and the number of steps executed so far.\n",
    "    replay_buffer_size: int\n",
    "        How many memories to store in the replay buffer.\n",
    "    batch_size: int\n",
    "        How many transitions to sample each time experience is replayed.\n",
    "    gamma: float\n",
    "        Discount Factor\n",
    "    learning_starts: int\n",
    "        After how many environment steps to start replaying experiences\n",
    "    learning_freq: int\n",
    "        How many steps of environment to take between every experience replay\n",
    "    frame_history_len: int\n",
    "        How many past frames to include as input to the model.\n",
    "    target_update_freq: int\n",
    "        How many experience replay rounds (not steps!) to perform between\n",
    "        each update to the target Q network\n",
    "    \"\"\"\n",
    "    assert type(env.observation_space) == gym.spaces.Box\n",
    "    assert type(env.action_space)      == gym.spaces.Discrete\n",
    "\n",
    "    ###############\n",
    "    # BUILD MODEL #\n",
    "    ###############\n",
    "\n",
    "    if len(env.observation_space.shape) == 1:\n",
    "        # This means we are running on low-dimensional observations (e.g. RAM)\n",
    "        input_arg = env.observation_space.shape[0]\n",
    "    else:\n",
    "        img_h, img_w, img_c = env.observation_space.shape\n",
    "        input_arg = frame_history_len * img_c\n",
    "    num_actions = env.action_space.n\n",
    "\n",
    "    # Construct an epilson greedy policy with given exploration schedule\n",
    "    def select_epilson_greedy_action(model, obs, t):\n",
    "        sample = random.random()\n",
    "        eps_threshold = exploration.value(t)\n",
    "        if sample > eps_threshold:\n",
    "            obs = torch.from_numpy(obs).type(dtype).unsqueeze(0) / 255.0\n",
    "            # Use volatile = True if variable is only used in inference mode, i.e. donâ€™t save the history\n",
    "            return model(Variable(obs, volatile=True)).data.max(1)[1].cpu()\n",
    "        else:\n",
    "            return torch.IntTensor([[random.randrange(num_actions)]])\n",
    "\n",
    "    # Initialize target q function and q function\n",
    "    Q = q_func(input_arg, num_actions).type(dtype)\n",
    "    target_Q = q_func(input_arg, num_actions).type(dtype)\n",
    "\n",
    "    # Construct Q network optimizer function\n",
    "    optimizer = optimizer_spec.constructor(Q.parameters(), **optimizer_spec.kwargs)\n",
    "\n",
    "    # Construct the replay buffer\n",
    "    replay_buffer = ReplayBuffer(replay_buffer_size, frame_history_len)\n",
    "\n",
    "    ###############\n",
    "    # RUN ENV     #\n",
    "    ###############\n",
    "    num_param_updates = 0\n",
    "    mean_episode_reward = -float('nan')\n",
    "    best_mean_episode_reward = -float('inf')\n",
    "    last_obs = env.reset()\n",
    "    LOG_EVERY_N_STEPS = 10000\n",
    "\n",
    "    for t in count():\n",
    "        ### Check stopping criterion\n",
    "        if stopping_criterion is not None and stopping_criterion(env):\n",
    "            break\n",
    "\n",
    "        ### Step the env and store the transition\n",
    "        # Store lastest observation in replay memory and last_idx can be used to store action, reward, done\n",
    "        last_idx = replay_buffer.store_frame(last_obs)\n",
    "        # encode_recent_observation will take the latest observation\n",
    "        # that you pushed into the buffer and compute the corresponding\n",
    "        # input that should be given to a Q network by appending some\n",
    "        # previous frames.\n",
    "        recent_observations = replay_buffer.encode_recent_observation()\n",
    "\n",
    "        # Choose random action if not yet start learning\n",
    "        if t > learning_starts:\n",
    "            action = select_epilson_greedy_action(Q, recent_observations, t)[0, 0]\n",
    "        else:\n",
    "            action = random.randrange(num_actions)\n",
    "        # Advance one step\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        # clip rewards between -1 and 1\n",
    "        reward = max(-1.0, min(reward, 1.0))\n",
    "        # Store other info in replay memory\n",
    "        replay_buffer.store_effect(last_idx, action, reward, done)\n",
    "        # Resets the environment when reaching an episode boundary.\n",
    "        if done:\n",
    "            obs = env.reset()\n",
    "        last_obs = obs\n",
    "\n",
    "        ### Perform experience replay and train the network.\n",
    "        # Note that this is only done if the replay buffer contains enough samples\n",
    "        # for us to learn something useful -- until then, the model will not be\n",
    "        # initialized and random actions should be taken\n",
    "        if (t > learning_starts and\n",
    "                t % learning_freq == 0 and\n",
    "                replay_buffer.can_sample(batch_size)):\n",
    "            # Use the replay buffer to sample a batch of transitions\n",
    "            # Note: done_mask[i] is 1 if the next state corresponds to the end of an episode,\n",
    "            # in which case there is no Q-value at the next state; at the end of an\n",
    "            # episode, only the current state reward contributes to the target\n",
    "            obs_batch, act_batch, rew_batch, next_obs_batch, done_mask = replay_buffer.sample(batch_size)\n",
    "            # Convert numpy nd_array to torch variables for calculation\n",
    "            obs_batch = Variable(torch.from_numpy(obs_batch).type(dtype) / 255.0)\n",
    "            act_batch = Variable(torch.from_numpy(act_batch).long())\n",
    "            rew_batch = Variable(torch.from_numpy(rew_batch))\n",
    "            next_obs_batch = Variable(torch.from_numpy(next_obs_batch).type(dtype) / 255.0)\n",
    "            not_done_mask = Variable(torch.from_numpy(1 - done_mask)).type(dtype)\n",
    "\n",
    "            if USE_CUDA:\n",
    "                act_batch = act_batch.cuda()\n",
    "                rew_batch = rew_batch.cuda()\n",
    "\n",
    "            # Compute current Q value, q_func takes only state and output value for every state-action pair\n",
    "            # We choose Q based on action taken.\n",
    "            current_Q_values = Q(obs_batch).gather(1, act_batch.unsqueeze(1))\n",
    "            # Compute next Q value based on which action gives max Q values\n",
    "            # Detach variable from the current graph since we don't want gradients for next Q to propagated\n",
    "            next_max_q = target_Q(next_obs_batch).detach().max(1)[0]\n",
    "            next_Q_values = not_done_mask * next_max_q\n",
    "            # Compute the target of the current Q values\n",
    "            target_Q_values = rew_batch + (gamma * next_Q_values)\n",
    "            # Compute Bellman error\n",
    "            bellman_error = target_Q_values - current_Q_values\n",
    "            # clip the bellman error between [-1 , 1]\n",
    "            clipped_bellman_error = bellman_error.clamp(-1, 1)\n",
    "            # Note: clipped_bellman_delta * -1 will be right gradient\n",
    "            d_error = clipped_bellman_error * -1.0\n",
    "            # Clear previous gradients before backward pass\n",
    "            optimizer.zero_grad()\n",
    "            # run backward pass\n",
    "            current_Q_values.backward(d_error.data.unsqueeze(1))\n",
    "\n",
    "            # Perfom the update\n",
    "            optimizer.step()\n",
    "            num_param_updates += 1\n",
    "\n",
    "            # Periodically update the target network by Q network to target Q network\n",
    "            if num_param_updates % target_update_freq == 0:\n",
    "                target_Q.load_state_dict(Q.state_dict())\n",
    "\n",
    "        ### 4. Log progress and keep track of statistics\n",
    "        episode_rewards = get_wrapper_by_name(env, \"Monitor\").get_episode_rewards()\n",
    "        if len(episode_rewards) > 0:\n",
    "            mean_episode_reward = np.mean(episode_rewards[-100:])\n",
    "        if len(episode_rewards) > 100:\n",
    "            best_mean_episode_reward = max(best_mean_episode_reward, mean_episode_reward)\n",
    "\n",
    "        Statistic[\"mean_episode_rewards\"].append(mean_episode_reward)\n",
    "        Statistic[\"best_mean_episode_rewards\"].append(best_mean_episode_reward)\n",
    "\n",
    "        if t % LOG_EVERY_N_STEPS == 0 and t > learning_starts:\n",
    "            print(\"Timestep %d\" % (t,))\n",
    "            print(\"mean reward (100 episodes) %f\" % mean_episode_reward)\n",
    "            print(\"best mean reward %f\" % best_mean_episode_reward)\n",
    "            print(\"episodes %d\" % len(episode_rewards))\n",
    "            print(\"exploration %f\" % exploration.value(t))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            # Dump statistics to pickle\n",
    "            with open('statistics.pkl', 'wb') as f:\n",
    "                pickle.dump(Statistic, f)\n",
    "                print(\"Saved to %s\" % 'results/statistics.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-14 09:40:05,419] Making new env: PongNoFrameskip-v4\n",
      "[2017-07-14 09:40:05,840] Clearing 14 monitor files from previous run (because force=True was provided)\n",
      "[2017-07-14 09:40:07,897] Starting new video recorder writing to /users/aditya.a/cvit_schools/cvitmlss17/lab5/results/pong/openaigym.video.0.16263.video000000.mp4\n",
      "[2017-07-14 09:40:11,194] Starting new video recorder writing to /users/aditya.a/cvit_schools/cvitmlss17/lab5/results/pong/openaigym.video.0.16263.video000001.mp4\n",
      "[2017-07-14 09:40:22,678] Starting new video recorder writing to /users/aditya.a/cvit_schools/cvitmlss17/lab5/results/pong/openaigym.video.0.16263.video000008.mp4\n",
      "[2017-07-14 09:40:51,171] Starting new video recorder writing to /users/aditya.a/cvit_schools/cvitmlss17/lab5/results/pong/openaigym.video.0.16263.video000027.mp4\n",
      "[2017-07-14 09:41:54,521] Starting new video recorder writing to /users/aditya.a/cvit_schools/cvitmlss17/lab5/results/pong/openaigym.video.0.16263.video000064.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestep 60000\n",
      "mean reward (100 episodes) -20.312500\n",
      "best mean reward -inf\n",
      "episodes 64\n",
      "exploration 0.946000\n",
      "Saved to results/statistics.pkl\n",
      "Timestep 70000\n",
      "mean reward (100 episodes) -20.266667\n",
      "best mean reward -inf\n",
      "episodes 75\n",
      "exploration 0.937000\n",
      "Saved to results/statistics.pkl\n",
      "Timestep 80000\n",
      "mean reward (100 episodes) -20.197674\n",
      "best mean reward -inf\n",
      "episodes 86\n",
      "exploration 0.928000\n",
      "Saved to results/statistics.pkl\n",
      "Timestep 90000\n",
      "mean reward (100 episodes) -20.237113\n",
      "best mean reward -inf\n",
      "episodes 97\n",
      "exploration 0.919000\n",
      "Saved to results/statistics.pkl\n",
      "Timestep 100000\n",
      "mean reward (100 episodes) -20.220000\n",
      "best mean reward -20.200000\n",
      "episodes 107\n",
      "exploration 0.910000\n",
      "Saved to results/statistics.pkl\n",
      "Timestep 110000\n",
      "mean reward (100 episodes) -20.200000\n",
      "best mean reward -20.200000\n",
      "episodes 118\n",
      "exploration 0.901000\n",
      "Saved to results/statistics.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-14 09:45:43,763] Starting new video recorder writing to /users/aditya.a/cvit_schools/cvitmlss17/lab5/results/pong/openaigym.video.0.16263.video000125.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestep 120000\n",
      "mean reward (100 episodes) -20.170000\n",
      "best mean reward -20.170000\n",
      "episodes 129\n",
      "exploration 0.892000\n",
      "Saved to results/statistics.pkl\n",
      "Timestep 130000\n",
      "mean reward (100 episodes) -20.170000\n",
      "best mean reward -20.150000\n",
      "episodes 140\n",
      "exploration 0.883000\n",
      "Saved to results/statistics.pkl\n",
      "Timestep 140000\n",
      "mean reward (100 episodes) -20.130000\n",
      "best mean reward -20.130000\n",
      "episodes 150\n",
      "exploration 0.874000\n",
      "Saved to results/statistics.pkl\n",
      "Timestep 150000\n",
      "mean reward (100 episodes) -20.130000\n",
      "best mean reward -20.120000\n",
      "episodes 161\n",
      "exploration 0.865000\n",
      "Saved to results/statistics.pkl\n",
      "Timestep 160000\n",
      "mean reward (100 episodes) -20.150000\n",
      "best mean reward -20.120000\n",
      "episodes 172\n",
      "exploration 0.856000\n",
      "Saved to results/statistics.pkl\n",
      "Timestep 170000\n",
      "mean reward (100 episodes) -20.220000\n",
      "best mean reward -20.120000\n",
      "episodes 183\n",
      "exploration 0.847000\n",
      "Saved to results/statistics.pkl\n",
      "Timestep 180000\n",
      "mean reward (100 episodes) -20.250000\n",
      "best mean reward -20.120000\n",
      "episodes 194\n",
      "exploration 0.838000\n",
      "Saved to results/statistics.pkl\n",
      "Timestep 190000\n",
      "mean reward (100 episodes) -20.260000\n",
      "best mean reward -20.120000\n",
      "episodes 205\n",
      "exploration 0.829000\n",
      "Saved to results/statistics.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-14 09:49:53,906] Starting new video recorder writing to /users/aditya.a/cvit_schools/cvitmlss17/lab5/results/pong/openaigym.video.0.16263.video000216.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestep 200000\n",
      "mean reward (100 episodes) -20.270000\n",
      "best mean reward -20.120000\n",
      "episodes 216\n",
      "exploration 0.820000\n",
      "Saved to results/statistics.pkl\n",
      "Timestep 210000\n",
      "mean reward (100 episodes) -20.330000\n",
      "best mean reward -20.120000\n",
      "episodes 227\n",
      "exploration 0.811000\n",
      "Saved to results/statistics.pkl\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    ## Set Gym\n",
    "    # Get Atari games.\n",
    "    atari = gym.benchmark_spec('Atari40M')\n",
    "\n",
    "    # Change the index to select a different game.\n",
    "    task = atari.tasks[PONG]\n",
    "    num_timesteps = task.max_timesteps\n",
    "    \n",
    "    ## Run training\n",
    "    seed = 0        # Use a seed of zero\n",
    "    env = get_env(task, seed)\n",
    "    \n",
    "    def stopping_criterion(env):\n",
    "        # notice that here t is the number of steps of the wrapped env,\n",
    "        # which is different from the number of steps in the underlying env\n",
    "        return get_wrapper_by_name(env, \"Monitor\").get_total_steps() >= num_timesteps\n",
    "    \n",
    "    optimizer_spec = OptimizerSpec(\n",
    "        constructor=optim.RMSprop,\n",
    "        kwargs=dict(lr=LEARNING_RATE, alpha=ALPHA, eps=EPS),\n",
    "    )\n",
    "    \n",
    "    exploration_schedule = LinearSchedule(1000000, 0.1)\n",
    "    \n",
    "    dqn_learing(\n",
    "        env=env,\n",
    "        q_func=DQN,\n",
    "        optimizer_spec=optimizer_spec,\n",
    "        exploration=exploration_schedule,\n",
    "        stopping_criterion=stopping_criterion,\n",
    "        replay_buffer_size=REPLAY_BUFFER_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        gamma=GAMMA,\n",
    "        learning_starts=LEARNING_STARTS,\n",
    "        learning_freq=LEARNING_FREQ,\n",
    "        frame_history_len=FRAME_HISTORY_LEN,\n",
    "        target_update_freq=TARGET_UPDATE_FREQ,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f57648dcbe0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f57647a3710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Statistic[\"mean_episode_rewards\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f575fb8f2e8>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD8CAYAAABkbJM/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5764444eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Statistic[\"best_mean_episode_rewards\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
